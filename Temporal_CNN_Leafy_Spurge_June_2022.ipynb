{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lake-thomas/spurge-temporal-cnn/blob/main/Temporal_CNN_Leafy_Spurge_June_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F39J0K2oJi9c"
      },
      "source": [
        "# Introduction May 2022\n",
        "This is a working Python notebook to implement Google Earth Engine <> TensorFlow for mapping invasive plant species from a time-series of Landsat imagery. In this example, the inputs are invasive species occurrence records from public databases. The model uses 1D-Conv layers in a temporal CNN framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr763hr2WfRI"
      },
      "outputs": [],
      "source": [
        "# Cloud Authentication \n",
        "# Required When Using Default Google Cloud (i.e. Not Using a Hosted VM Runtime Environment)\n",
        "\n",
        "#Connect to hosted VM https://console.cloud.google.com/marketplace/product/colab-marketplace-image-public/colab?project=pacific-engine-346519\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKPzal69MnDx"
      },
      "source": [
        "Authenticate Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyn_VJYmJX4I",
        "outputId": "c2a8195a-7928-4d39-fce2-18da871cf0e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=H_aPP75r-fb3dkupYQBZWiKn7tWmJ1F6Au-Z3EPbZtY&tc=PIVx9D0Xj48D6BnTL87I909ynCesdytJUN8ocpuOxS8&cc=eP7dr-llVmwWYcZiNI_eLTdY_IItERcypV8k3ziW5zo\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWglxS4sNgKCOEFdk-xrhC3L2-5eJRjoUn7u3xCs7DPYxBXGqc81k8Y\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8EWkQ2NMxMU"
      },
      "source": [
        "Mount google drive and google cloud storage drives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h96mJ5p1JX6W",
        "outputId": "208e419d-6324-44f2-b8a7-31361663e9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive for CSV reading\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Used to export to google cloud\n",
        "from google.cloud import storage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPct6V2eMzIc"
      },
      "source": [
        "Install packages not available on Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX3X-TFINEgb"
      },
      "outputs": [],
      "source": [
        "#Ignore Warnings and Errors\n",
        "!pip install geemap\n",
        "import geemap #advanced python function for GEE\n",
        "!pip install geopandas\n",
        "import geopandas #Pandas library to handle geospatial data\n",
        "!pip install fsspec\n",
        "import fsspec # file system specification\n",
        "!pip install gcsfs\n",
        "import gcsfs #google cloud file system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsOzkKfM15a"
      },
      "source": [
        "Load other packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UKD0skbJX8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import dirname, basename, isfile, join\n",
        "import io\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pprint\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "import csv\n",
        "from functools import reduce\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsj2ajIKNCkA"
      },
      "outputs": [],
      "source": [
        "# Import temporalCNN python files for Temporal CNN Deep Learning analyses\n",
        "# https://github.com/charlotte-pel/temporalCNN/\n",
        "\n",
        "import sys\n",
        "\n",
        "# Import from ~/sits folder\n",
        "# Contains readingsits.py file to read and compute spectral features on SITS\n",
        "sys.path.append(\"/content/drive/MyDrive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/sits\")\n",
        "import readingsits\n",
        "\n",
        "# Import from ~/deeplearning folder\n",
        "# Contains multiple .py files with varying DL architectures \n",
        "sys.path.append(\"/content/drive/MyDrive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/deeplearning\")\n",
        "\n",
        "import architecture_features\n",
        "import architecture_complexity\n",
        "import architecture_rnn\n",
        "import architecture_regul\n",
        "import architecture_batchsize\n",
        "import architecture_depth\n",
        "import architecture_spectro_temporal\n",
        "import architecture_pooling\n",
        "\n",
        "# Import from ~/outputfiles folder\n",
        "# Contains evaluation.py and save.py files with fucntions to compute summary statistics, write predictions, and create confusion matrices\n",
        "sys.path.append(\"/content/drive/MyDrive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/outputfiles\")\n",
        "\n",
        "import evaluation\n",
        "import save\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq3iA11_M4qF"
      },
      "source": [
        "Import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxSPPJwzJX-z",
        "outputId": "ea03a1c5-56c9-4806-eb6b-6bcff710b098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow setup.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# Keras setup.\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Flatten\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, Flatten, Lambda, SpatialDropout1D, Concatenate\n",
        "from keras.layers import Conv1D, Conv2D, AveragePooling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.callbacks import Callback, ModelCheckpoint, History, EarlyStopping\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import backend as K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQRJesf9Ke_v"
      },
      "source": [
        "#Get names of .csv files from Google Cloud and format training data into Pandas DF\n",
        "\n",
        "Function takes data exported from notebook \"Temporal CNN Leafy Spurge Demo April 2022.ipynb\", which contains script to extract Landsat time series data on NLDC labelled points.\n",
        "\n",
        "Reading data solution from: https://stackoverflow.com/questions/56823082/reading-all-csv-files-from-a-google-storage-bucket-into-one-large-pandas-df-th"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJmflV9tJYBD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define google bucket hosting the .csv files for training\n",
        "outputBucket = 'landcover_samples_nlcd2019_onemillionpoints'\n",
        "\n",
        "# Make sure the bucket exists.\n",
        "print('Found Cloud Storage bucket.' if tf.io.gfile.exists('gs://' + outputBucket) \n",
        "  else 'Output Cloud Storage bucket does not exist.')\n",
        "\n",
        "storage_client = storage.Client()\n",
        "\n",
        "source_bucket = storage_client.bucket(outputBucket)\n",
        "\n",
        "#Select column names from landsat csv exported data frames, drop excess bands (QA, system:index, class_x_x, etc)\n",
        "col_names = [\"BlueMarchApril2018\",\"GreenMarchApril2018\",\"NDVIMarchApril2018\",\"NIRMarchApril2018\",\"RedMarchApril2018\",\"SWIR1MarchApril2018\",\"SWIR2MarchApril2018\",\n",
        "             \"BlueMayJune2018\",\"GreenMayJune2018\",\"NDVIMayJune2018\",\"NIRMayJune2018\",\"RedMayJune2018\",\"SWIR1MayJune2018\",\"SWIR2MayJune2018\",\n",
        "             \"BlueJulyAug2018\",\"GreenJulyAug2018\",\"NDVIJulyAug2018\",\"NIRJulyAug2018\",\"RedJulyAug2018\",\"SWIR1JulyAug2018\",\"SWIR2JulyAug2018\",\n",
        "             \"BlueMarchApril2019\",\"GreenMarchApril2019\",\"NDVIMarchApril2019\",\"NIRMarchApril2019\",\"RedMarchApril2019\",\"SWIR1MarchApril2019\",\"SWIR2MarchApril2019\",\n",
        "             \"BlueMayJune2019\",\"GreenMayJune2019\",\"NDVIMayJune2019\",\"NIRMayJune2019\",\"RedMayJune2019\",\"SWIR1MayJune2019\",\"SWIR2MayJune2019\",\n",
        "             \"BlueJulyAug2019\",\"GreenJulyAug2019\",\"NDVIJulyAug2019\",\"NIRJulyAug2019\",\"RedJulyAug2019\",\"SWIR1JulyAug2019\",\"SWIR2JulyAug2019\",\n",
        "             \"BlueMarchApril2020\",\"GreenMarchApril2020\",\"NDVIMarchApril2020\",\"NIRMarchApril2020\",\"RedMarchApril2020\",\"SWIR1MarchApril2020\",\"SWIR2MarchApril2020\",\n",
        "             \"BlueMayJune2020\",\"GreenMayJune2020\",\"NDVIMayJune2020\",\"NIRMayJune2020\",\"RedMayJune2020\",\"SWIR1MayJune2020\",\"SWIR2MayJune2020\",\n",
        "             \"BlueJulyAug2020\",\"GreenJulyAug2020\",\"NDVIJulyAug2020\",\"NIRJulyAug2020\",\"RedJulyAug2020\",\"SWIR1JulyAug2020\",\"SWIR2JulyAug2020\",\"class\"]\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "#Read in all data frames, append each to make one large dataframe\n",
        "for file in list(source_bucket.list_blobs()):\n",
        "    file_path=\"gs://{}/{}\".format(file.bucket.name, file.name)\n",
        "    df = df.append(pd.read_csv(file_path, header='infer'))\n",
        "\n",
        "\n",
        "#Subset column names to only imagery bands (9 dates * 7 bands = 63 columns + 1 column class index)\n",
        "df_imagery_class = df[col_names]\n",
        "\n",
        "#Move last column (class ID) to first index\n",
        "cls_column = df_imagery_class.pop(\"class\")\n",
        "df_imagery_class.insert(0, \"class\", cls_column)\n",
        "\n",
        "#Number of class instances in the dataset\n",
        "df_imagery_class['class'].value_counts()\n",
        "\n",
        "#remove first column index\n",
        "df_imagery_class.set_index('class', inplace=True)\n",
        "\n",
        "#add column in second position as an index\n",
        "df_imagery_class.insert(0, \"index\", range(1, 1 + len(df_imagery_class)))\n",
        "\n",
        "#Number of rows/columns in dataset\n",
        "df_imagery_class.shape\n",
        "\n",
        "#Write full dataframe to CSV\n",
        "#Export format as rows [classID, index, band_values/timeseries...] with no header\n",
        "#df_imagery_class.to_csv(\"/content/drive/My Drive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example/full_dataset.csv\", header=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnNrVqwGhNtM"
      },
      "source": [
        "#Divide full dataset into training and testing subsets, export to csv\n",
        "\n",
        "Use Scikit Learn train test split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "983F9wmthNJ4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df_imagery_class, test_size=0.1)\n",
        "\n",
        "#Number of rows/columns in dataset\n",
        "print(train_df.shape, test_df.shape)\n",
        "\n",
        "#Write full dataframe to CSV\n",
        "#Export format as rows [classID, index, band_values/timeseries...] with no header\n",
        "train_df.to_csv(\"/content/drive/My Drive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example/train_dataset_2019_full_may2022.csv\", header=False)\n",
        "test_df.to_csv(\"/content/drive/My Drive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example/test_dataset_2019_full_may2022.csv\", header=False)\n",
        "\n",
        "\n",
        "#Ask how the training/testing dataset divided classes (how many samples/class)\n",
        "train_df.reset_index(inplace=True)\n",
        "test_df.reset_index(inplace=True)\n",
        "\n",
        "#Number of class instances in the training and testing dataset\n",
        "train_df['class'].value_counts()\n",
        "test_df['class'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymai8TH8YsWl"
      },
      "source": [
        "#Read, Reshape, and Normalize Training Dataset for Temporal CNN\n",
        "\n",
        "https://github.com/charlotte-pel/temporalCNN/blob/master/run_archi.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrXJmkxQJYHo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Verify the file exists and can be opened\n",
        "open(\"/content/drive/MyDrive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example/train_dataset_2019_full_may2022.csv\").read()\n",
        "\n",
        "res_path = '/content/drive/My Drive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography'\n",
        "sits_path = '/content/drive/My Drive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example'\n",
        "feature = \"SB\" #use only spectral bands provided (do not compute new bands, like NDVI, which are already computed)\n",
        "noarchi = 0\n",
        "norun = 0\n",
        "\n",
        "\n",
        "#-- Creating output path if does not exist\n",
        "if not os.path.exists(res_path):\n",
        "  print(\"ResPath DNE\")\n",
        "  os.makedirs(res_path)\n",
        "\t\n",
        "\t#---- Parameters to set\n",
        "n_channels = 7 #-- B G NDVI NIR Red SWIR1 SWIR2\n",
        "val_rate = 0.1\n",
        "\n",
        "\t#---- Evaluated metrics\n",
        "eval_label = ['OA', 'train_loss', 'train_time', 'test_time']\t\n",
        "\t\n",
        "\t#---- String variables\n",
        "train_str = 'train_dataset_2019_full_may2022'\n",
        "test_str = 'test_dataset_2019_full_may2022'\t\t\t\t\t\n",
        "\n",
        "\t#---- Get filenames\n",
        "train_file = sits_path + '/' + train_str + '.csv'\n",
        "test_file = sits_path + '/' + test_str + '.csv'\n",
        "print(\"train_file: \", train_file)\n",
        "print(\"test_file: \", test_file)\n",
        "\t\n",
        "\t#---- output files\t\t\t\n",
        "res_path = res_path + '/Archi' + str(noarchi) + '/'\n",
        "if not os.path.exists(res_path):\n",
        "  os.makedirs(res_path)\n",
        "  print(\"noarchi: \", noarchi)\n",
        "\t\n",
        "str_result = feature + '-' + train_str + '-noarchi' + str(noarchi) + '-norun' + str(norun) \n",
        "res_file = res_path + '/resultOA-' + str_result + '.csv'\n",
        "res_mat = np.zeros((len(eval_label),1))\n",
        "traintest_loss_file = res_path + '/trainingHistory-' + str_result + '.csv'\n",
        "conf_file = res_path + '/confMatrix-' + str_result + '.csv'\n",
        "out_model_file = res_path + '/bestmodel-' + str_result + '.h5'\n",
        "\n",
        "\n",
        "\n",
        "\t#---- Downloading\n",
        "X_train, polygon_ids_train, y_train = readingsits.readSITSData(train_file)\n",
        "print(X_train) #verify spectral band data looks correct\n",
        "print(X_train.shape) #num_samples, 63 bands (9 timesteps * 7 bands/timestep = 63)\n",
        "\n",
        "X_test,  polygon_ids_test, y_test = readingsits.readSITSData(test_file)\n",
        "print(X_test)  #verify spectral band data looks correct\n",
        "print(X_test.shape) #num_samples, 63 bands (9 timesteps * 7 bands/timestep = 63)\n",
        "\n",
        "n_classes_test = len(np.unique(y_test))\n",
        "print(n_classes_test)\n",
        "n_classes_train = len(np.unique(y_train))\n",
        "print(n_classes_train)\n",
        "\n",
        "#Check equal number of classes in training and testing dataset\n",
        "if(n_classes_test != n_classes_train):\n",
        "  print(\"WARNING: different number of classes in train and test\")\n",
        "\n",
        "n_classes = max(n_classes_train, n_classes_test)\n",
        "y_train_one_hot = to_categorical(y_train) #specify number of classes explicity - may need to recode classes sequentially (1-9) to work correctly\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "print(y_train_one_hot) #verify one hot encoding was successful\n",
        "print(y_test_one_hot)\n",
        "\t\n",
        "\t#---- Adding the features and reshaping the data if necessary\n",
        "X_train = readingsits.addingfeat_reshape_data(X_train, feature, n_channels) #Feature = \"SB\" (spectral bands)\n",
        "\n",
        "print(X_train[0, :, :])\n",
        "print(X_train.shape) #verify reshape was successful, now num_samples, num_timesteps, num_bands\n",
        "\n",
        "X_test = readingsits.addingfeat_reshape_data(X_test, feature, n_channels)\t\t\n",
        "print(X_test.shape)\n",
        "\n",
        "#---- Normalizing the data per band (Do we want to normalize across years or within one year?)\n",
        "minMaxVal_file = '.'.join(out_model_file.split('.')[0:-1])\n",
        "minMaxVal_file = minMaxVal_file + '_minMax.txt'\n",
        "\n",
        "if not os.path.exists(minMaxVal_file): \n",
        "  min_per, max_per = readingsits.computingMinMax(X_train) #compute 98% min/max (per = 2) on bands\n",
        "  readingsits.save_minMaxVal(minMaxVal_file, min_per, max_per)\n",
        "else:\n",
        "  min_per, max_per = readingsits.read_minMaxVal(minMaxVal_file)\n",
        "\n",
        "print(min_per, max_per) #minimum and maximum values per band, for 98% normalization\n",
        "\n",
        "X_train =  readingsits.normalizingData(X_train, min_per, max_per)\n",
        "X_test =  readingsits.normalizingData(X_test, min_per, max_per)\n",
        "\n",
        "print(X_train[0:1, :, :]) #verify normalization worked as intended, values zero centered and scaled\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a2gBh3WkqAm"
      },
      "source": [
        "#Create Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P3JE87lxN8L",
        "outputId": "dfb1e26e-9272-4ba1-ab05-83b8e39d0c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "9\n",
            "(325701, 9, 7) (325701, 10) (36190, 9, 7) (36190, 10) (40211, 9, 7) (40211, 10)\n"
          ]
        }
      ],
      "source": [
        "#---- Extracting a validation set (if necesary)\n",
        "if val_rate > 0:\n",
        "  #Number of samples to take from Training dataset based on validation rate\n",
        "  val_num_samples = int(math.ceil(X_train.shape[0] * val_rate))\n",
        "\n",
        "  #Select random indices for val_num_samples to select validation set\n",
        "  val_indices = random.sample(range(1, X_train.shape[0]), val_num_samples)\n",
        "  #remove these indices from the training set\n",
        "  train_indices = np.delete(range(1, X_train.shape[0]), val_indices)\n",
        "\n",
        "  #Create training and validation sets \n",
        "  X_val = X_train[val_indices, :, :]\n",
        "  y_val = y_train[val_indices]\n",
        "  X_train = X_train[train_indices, :, :]\n",
        "  y_train = y_train[train_indices]\n",
        "\n",
        "  #--- Computing the one-hot encoding (recomputing it for train)\n",
        "  y_train_one_hot = to_categorical(y_train)\n",
        "  y_val_one_hot = to_categorical(y_val)\n",
        "\n",
        "  n_classes_val = len(np.unique(y_val))\n",
        "  print(n_classes_val)\n",
        "  n_classes_train = len(np.unique(y_train))\n",
        "  print(n_classes_train)\n",
        "\n",
        "  #Check equal number of classes in training and testing dataset\n",
        "  if(n_classes_val != n_classes_train):\n",
        "    print(\"WARNING: different number of classes in train and test\")\n",
        "  \n",
        "\n",
        "print(X_train.shape, y_train_one_hot.shape, X_val.shape, y_val_one_hot.shape, X_test.shape, y_test_one_hot.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phjKG-SAku4f"
      },
      "source": [
        "#Define model architecture and model variables, then train the model\n",
        "\n",
        "Model architectures https://github.com/charlotte-pel/temporalCNN/blob/master/deeplearning/architecture_complexity.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "zE8pgoAThRpz",
        "outputId": "d3fe9e8b-ab98-4acc-fd2c-f2057cd9ad8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1273/1273 [==============================] - 58s 45ms/step - loss: 0.0276 - accuracy: 0.1734 - val_loss: 0.0992 - val_accuracy: 0.2225\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Custom Model Architecture inspired by Allred at al. 2021\n",
        "\n",
        "#Get input sizes\n",
        "m, L, depth = X_train.shape\n",
        "input_shape = (L, depth)\n",
        "\n",
        "#-- parameters of the architecture\n",
        "l2_rate = 1.e-6\n",
        "dropout_rate = 0.10\n",
        "nbclasses = 10\n",
        "\n",
        "X_input = tf.keras.Input(input_shape)\n",
        "\n",
        "X = X_input\n",
        "\n",
        "X = Conv1D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\", dilation_rate = 1, kernel_regularizer = l2(1.e-6), kernel_initializer = \"he_normal\")(X)\n",
        "#X = BatchNormalization(axis=-1)(X)\n",
        "X = Activation('relu')(X)\n",
        "X = Dropout(dropout_rate)(X)\n",
        "X = Conv1D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\", dilation_rate = 2, kernel_regularizer = l2(1.e-6), kernel_initializer = \"he_normal\")(X)\n",
        "#X = BatchNormalization(axis=-1)(X)\n",
        "X = Activation('relu')(X)\n",
        "X = Dropout(dropout_rate)(X)\n",
        "#X = AveragePooling1D(pool_size=2)(X)\n",
        "X = Conv1D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", dilation_rate = 4, kernel_regularizer = l2(1.e-6), kernel_initializer = \"he_normal\")(X)\n",
        "#X = BatchNormalization(axis=-1)(X)\n",
        "X = Activation('relu')(X)\n",
        "X = Dropout(dropout_rate)(X)\n",
        "X = Flatten()(X)\n",
        "X = Dense(units = 512, kernel_initializer=\"he_normal\", kernel_regularizer=l2(1.e-6))(X)\n",
        "#X = BatchNormalization(axis=-1)(X)\n",
        "X = Activation('relu')(X)\n",
        "X = Dropout(dropout_rate)(X)\n",
        "out = Dense(nbclasses, activation = \"softmax\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(1.e-6))(X)\n",
        "\n",
        "model = tf.keras.Model(inputs = X_input, outputs = out, name = \"Custom_Temporal_CNN\")\n",
        "\n",
        "\n",
        "#Define Class Weights\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights =  class_weight.compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(y_train),\n",
        "                                        y = y_train                                                   \n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(y_train), class_weights))\n",
        "print(class_weights)\n",
        "\n",
        "class_weights = {0: 0.0001,\n",
        "                 1: 8.156186612576064,\n",
        "                 2: 3.5251315020455873,\n",
        "                 3: 30.983732876712327,\n",
        "                 4: 0.07975888744407467,\n",
        "                 5: 0.05826879417778994,\n",
        "                 6: 0.0388306490552271,\n",
        "                 7: 0.0370967576599387,\n",
        "                 8: 4.064353099730458,\n",
        "                 9: 13.428200371057514}\n",
        "\n",
        "\n",
        "###\n",
        "# Define Model Variables\n",
        "###\n",
        "\n",
        "# Model variables\n",
        "n_epochs = 5\n",
        "batch_size = 256\n",
        "lr = 0.0001 #recommended in Allred et al., 2021\n",
        "beta_1 = 0.9 #not used, but can be used to modify optimizer LR\n",
        "beta_2 = 0.999\n",
        "decay = 0.0\n",
        "\t\n",
        "#Model Optimizer\n",
        "#opt = tf.keras.optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, decay=decay)\n",
        "opt = tf.keras.optimizers.Adam(lr=lr)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer = opt, loss = \"mean_squared_error\", metrics = [\"accuracy\"])\n",
        "\t\n",
        "# Model callbacks\n",
        "checkpoint = ModelCheckpoint(out_model_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "#Plot Loss and Accuracy Callback\n",
        "class PlotLearning(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.f1 = []\n",
        "        self.val_f1 = []\n",
        "        \n",
        "        self.fig = plt.figure()\n",
        "        \n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        \n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.f1.append(logs.get('accuracy'))\n",
        "        self.val_f1.append(logs.get('val_accuracy'))\n",
        "        self.i += 1\n",
        "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        ax1.set_yscale('log')\n",
        "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
        "        ax1.plot(self.x, self.val_losses, label=\"val loss\")\n",
        "        ax1.legend()\n",
        "        \n",
        "        ax2.plot(self.x, self.f1, label=\"Acc\")\n",
        "        ax2.plot(self.x, self.val_f1, label=\"val Acc \")\n",
        "        ax2.legend()\n",
        "        \n",
        "        plt.show();\n",
        "        \n",
        "plot_losses = PlotLearning()\n",
        "\n",
        "callback_list = [plot_losses]\n",
        "\t\t\n",
        "\n",
        "start_train_time = time.time()\n",
        "\n",
        "hist = model.fit(x = X_train, y = y_train_one_hot, epochs = n_epochs,\n",
        "                 batch_size = batch_size, shuffle=True,\n",
        "                 validation_data=(X_val, y_val_one_hot),verbose=1, \n",
        "                 class_weight = class_weights, callbacks = [plot_losses])\n",
        "\n",
        "train_time = round(time.time()-start_train_time, 2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save/Load the trained model\n",
        "Export the trained model to TensorFlow SavedModel format in your cloud storage bucket. The Cloud Platform storage browser is useful for checking on these saved models.\n",
        "\n",
        "Call model.save to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, you can resume training from exactly where you left off.\n",
        "\n",
        "An entire model can be saved in two different file formats (SavedModel and HDF5). The TensorFlow SavedModel format is the default file format in TF2.x. However, models can be saved in HDF5 format. More details on saving entire models in the two file formats is described below.\n",
        "\n",
        "Saving a fully-functional model is very useful—you can load them in TensorFlow.js (Saved Model, HDF5) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (Saved Model, HDF5)\n",
        "\n",
        "*Custom objects (e.g. subclassed models or layers) require special attention when saving and loading. See the Saving custom objects section below"
      ],
      "metadata": {
        "id": "AUUfXo-_M-YD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to google cloud storage\n",
        "MODEL_DIR = 'gs://' + 'landsat-csv-bucket' + '/demo_pixel_model'\n",
        "model.save(MODEL_DIR, save_format='tf')\n",
        "\n",
        "# Load trained model from google cloud storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB8o-GwXM98Q",
        "outputId": "b0320f7b-d61e-408c-832b-4a8c229c8d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: gs://landsat-csv-bucket/demo_pixel_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEification\n",
        "\n",
        "EEIfication prepares the model for hosting on [Google AI Platform](https://cloud.google.com/ai-platform).  Learn more about EEification from [this doc](https://developers.google.com/earth-engine/tensorflow#interacting-with-models-hosted-on-ai-platform).  First, get (and SET) input and output names of the nodes.  **CHANGE THE OUTPUT NAME TO SOMETHING THAT MAKES SENSE FOR YOUR MODEL!**  Keep the input name of 'array', which is how you'll pass data into the model (as an array image)."
      ],
      "metadata": {
        "id": "2w9s1M4KO_iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.tools import saved_model_utils\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(MODEL_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
        "# AI Platform inputs and outputs, respectively.\n",
        "import json\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"output\"}) + \"'\"\n",
        "print(input_dict)\n",
        "print(output_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2VL48GJO-rI",
        "outputId": "b4e3f38b-6ae0-463e-dba7-c6dceed89a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'{\"serving_default_input_1:0\": \"array\"}'\n",
            "'{\"StatefulPartitionedCall:0\": \"output\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the EEifier\n",
        "\n",
        "The actual EEification is handled by the `earthengine model prepare` command.  Note that you will need to set your Cloud Project prior to running the command."
      ],
      "metadata": {
        "id": "4vZMwlorPjjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://' + 'landsat-csv-bucket' + '/eeified_pixel_model'\n",
        "\n",
        "# You need to set the project before using the model prepare command.\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {MODEL_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPMHUASO-z-",
        "outputId": "1466ebd3-a668-4cef-d186-3b66f2d9a6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved project id\n",
            "Warning: TensorFlow Addons not found. Models that use non-standard ops may not work.\n",
            "Success: model at 'gs://landsat-csv-bucket/eeified_pixel_model' is ready to be hosted in AI Platform.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy and host the EEified model on AI Platform\n",
        "\n",
        "Now there is another TensorFlow `SavedModel` stored in `EEIFIED_DIR` ready for hosting by AI Platform.  Do that from the `gcloud` command line tool, installed in the Colab runtime by default.  Be sure to specify a regional model with the `REGION` parameter.  Note that the `MODEL_NAME` must be unique.  If you already have a model by that name, either name a new model or a new version of the old model.  The [Cloud Console AI Platform models page](https://console.cloud.google.com/ai-platform/models) is useful for monitoring your models.\n",
        "\n",
        "**If you change anything about the trained model, you'll need to re-EEify it and create a new version!**"
      ],
      "metadata": {
        "id": "WWalSYs_RqXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PROJECT = 'pacific-engine-346519'\n",
        "MODEL_NAME = 'pixel_demo_model_may2022_test1'\n",
        "VERSION_NAME = 'v0'\n",
        "\n",
        "# This is a good region for hosting AI models.\n",
        "REGION = 'us-central1'\n",
        "\n",
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION}\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --runtime-version=2.3 \\\n",
        "  --python-version=3.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sr-Rz0fO-2t",
        "outputId": "7ec3bebd-75e5-4da4-e01c-a4de962b869f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "Created ai platform model [projects/pacific-engine-346519/models/pixel_demo_model_may2022_test1].\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n",
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to the hosted model from Earth Engine\n",
        "\n",
        "1. Generate the input imagery.  This should be done in exactly the same way as the training data were generated.  See [this example notebook](http://colab.research.google.com/github/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb) for details.\n",
        "2. Connect to the hosted model.\n",
        "3. Use the model to make predictions.\n",
        "4. Display the results.\n",
        "\n",
        "Note that it takes the model a couple minutes to spin up and make predictions."
      ],
      "metadata": {
        "id": "IsBzj7doZj-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define a function to transfer feature properties to a dictionary.\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)\n",
        "\n",
        "\n",
        "#Cloud Mask: https://gis.stackexchange.com/questions/274048/apply-cloud-mask-to-landsat-imagery-in-google-earth-engine-python-api\n",
        "def getQABits(image, start, end, mascara): \n",
        "    # Compute the bits we need to extract.\n",
        "    pattern = 0\n",
        "    for i in range(start,end+1):\n",
        "        pattern += 2**i\n",
        "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
        "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
        "\n",
        "\n",
        "#Saturated band Mask: https://gis.stackexchange.com/questions/363929/how-to-apply-a-bitmask-for-radiometric-saturation-qa-in-a-image-collection-eart\n",
        "def bitwiseExtract(value, fromBit, toBit):\n",
        "  maskSize = ee.Number(1).add(toBit).subtract(fromBit)\n",
        "  mask = ee.Number(1).leftShift(maskSize).subtract(1)\n",
        "  return value.rightShift(fromBit).bitwiseAnd(mask)\n",
        "\n",
        "\n",
        "#Function to mask out cloudy and saturated pixels and harmonize between Landsat 5/7/8 imagery \n",
        "def maskQuality(image):\n",
        "    # Select the QA band.\n",
        "    QA = image.select('QA_PIXEL')\n",
        "    # Get the internal_cloud_algorithm_flag bit.\n",
        "    sombra = getQABits(QA,3,3,'cloud_shadow')\n",
        "    nubes = getQABits(QA,5,5,'cloud')\n",
        "    #  var cloud_confidence = getQABits(QA,6,7,  'cloud_confidence')\n",
        "    cirrus_detected = getQABits(QA,9,9,'cirrus_detected')\n",
        "    #var cirrus_detected2 = getQABits(QA,8,8,  'cirrus_detected2')\n",
        "    #Return an image masking out cloudy areas.\n",
        "    QA_radsat = image.select('QA_RADSAT')\n",
        "    saturated = bitwiseExtract(QA_radsat, 1, 7)\n",
        "\n",
        "    #Apply the scaling factors to the appropriate bands.\n",
        "    def getFactorImg(factorNames):\n",
        "      factorList = image.toDictionary().select(factorNames).values()\n",
        "      return ee.Image.constant(factorList)\n",
        "\n",
        "    scaleImg = getFactorImg(['REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10'])\n",
        "\n",
        "    offsetImg = getFactorImg(['REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10'])\n",
        "    \n",
        "    scaled = image.select('SR_B.|ST_B10').multiply(scaleImg).add(offsetImg)\n",
        "\n",
        "    #Replace original bands with scaled bands and apply masks.\n",
        "    return image.addBands(scaled, None, True).updateMask(sombra.eq(0)).updateMask(nubes.eq(0).updateMask(cirrus_detected.eq(0).updateMask(saturated.eq(0))))\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for Landsat OLI.\n",
        "def renameOli(img):\n",
        "  return img.select(\n",
        "    ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'],\n",
        "    ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2'])\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm(img):\n",
        "  return img.select(\n",
        "    ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'],\n",
        "    ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2'])\n",
        "\n",
        "\n",
        "# Adding a NDVI band\n",
        "def addNDVI(image):\n",
        "  ndvi = image.normalizedDifference(['NIR', 'Red']).rename('NDVI')\n",
        "  return image.addBands([ndvi])\n",
        "\n",
        "\n",
        "def mapDates(image):\n",
        "  date = ee.Date(image.get('system:time_start')).format(\"YYYY-MM-dd\")\n",
        "  return image.addBands([date])\n",
        "\n",
        "# Prepares (renames) OLI images.\n",
        "def prepOli(img):\n",
        "  img = renameOli(img)\n",
        "  return img\n",
        "\n",
        "\n",
        "# Prepares (renames) TM/ETM+ images.\n",
        "def prepEtm(img):\n",
        "  orig = img\n",
        "  img = renameEtm(img)\n",
        "  return ee.Image(img.copyProperties(orig, orig.propertyNames()))\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameImageBands_TM(img, year, season):\n",
        "  return img.select(\n",
        "      ['Blue_median', 'Green_median', 'Red_median', 'NIR_median', \n",
        "       'SWIR1_median', 'SWIR2_median', 'NDVI_median'],\n",
        "      ['Blue'+str(season)+str(year), 'Green'+str(season)+str(year), 'Red'+str(season)+str(year), 'NIR'+str(season)+str(year),\n",
        "       'SWIR1'+str(season)+str(year), 'SWIR2'+str(season)+str(year), 'NDVI'+str(season)+str(year)])\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameImageBands_ETMOLI(img, year, season):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', \n",
        "       'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue'+str(season)+str(year), 'Green'+str(season)+str(year), 'Red'+str(season)+str(year), 'NIR'+str(season)+str(year),\n",
        "       'SWIR1'+str(season)+str(year), 'SWIR2'+str(season)+str(year), 'NDVI'+str(season)+str(year)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Load sample points from Denver, CO area (~500 points)\n",
        "pts = ee.FeatureCollection('users/lakex055/spurge_landcover_testpoints_denver_small')\n",
        "\n",
        "#Sample points given a year, here we want points sampled from three years of Landsat imagery centered on 2019 \n",
        "\n",
        "##########\n",
        "## 2018 ##\n",
        "##########\n",
        "\n",
        "etmColMarchApril2018 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2018-03-01', '2018-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "oliColMarchApril2018 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2018-03-01', '2018-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "MarchApril2018 = ee.ImageCollection([etmColMarchApril2018, oliColMarchApril2018])\n",
        "\n",
        "etmColMarchApril2018 = MarchApril2018.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_1(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue_median_1', 'Green_median_1', 'Red_median_1', 'NIR_median_1','SWIR1_median_1', 'SWIR2_median_1', 'NDVI_median_1'])\n",
        "\n",
        "etmColMarchApril2018 = renameEtm_median_1(etmColMarchApril2018)\n",
        "\n",
        "etmColMayJune2018 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2018-05-01', '2018-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "oliColMayJune2018 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2018-05-01', '2018-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "MayJune2018 = ee.ImageCollection([etmColMayJune2018, oliColMayJune2018])\n",
        "\n",
        "etmColMayJune2018 = MayJune2018.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_2(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue_median_2', 'Green_median_2', 'Red_median_2', 'NIR_median_2','SWIR1_median_2', 'SWIR2_median_2', 'NDVI_median_2'])\n",
        "\n",
        "etmColMayJune2018 = renameEtm_median_2(etmColMayJune2018)\n",
        "\n",
        "etmColJulyAug2018 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2018-07-01', '2018-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median') \\\n",
        "\n",
        "oliColJulyAug2018 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2018-07-01', '2018-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "JulyAug2018 = ee.ImageCollection([etmColJulyAug2018, oliColJulyAug2018])\n",
        "\n",
        "etmColJulyAug2018 = JulyAug2018.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_3(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue_median_3', 'Green_median_3', 'Red_median_3', 'NIR_median_3','SWIR1_median_3', 'SWIR2_median_3',  'NDVI_median_3'])\n",
        "\n",
        "etmColJulyAug2018 = renameEtm_median_3(etmColJulyAug2018)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########\n",
        "## 2019 ##\n",
        "##########\n",
        "\n",
        "etmColMarchApril2019 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2019-03-01', '2019-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "oliColMarchApril2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2019-03-01', '2019-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "MarchApril2019 = ee.ImageCollection([etmColMarchApril2019, oliColMarchApril2019])\n",
        "\n",
        "etmColMarchApril2019 = MarchApril2019.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_4(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue_median_4', 'Green_median_4', 'Red_median_4', 'NIR_median_4','SWIR1_median_4', 'SWIR2_median_4', 'NDVI_median_4'])\n",
        "\n",
        "etmColMarchApril2019 = renameEtm_median_4(etmColMarchApril2019)\n",
        "\n",
        "etmColMayJune2019 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2019-05-01', '2019-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "oliColMayJune2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2019-05-01', '2019-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "MayJune2019 = ee.ImageCollection([etmColMayJune2019, oliColMayJune2019])\n",
        "\n",
        "etmColMayJune2019 = MayJune2019.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_5(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median',  'NDVI_median_median'],\n",
        "      ['Blue_median_5', 'Green_median_5', 'Red_median_5', 'NIR_median_5','SWIR1_median_5', 'SWIR2_median_5',  'NDVI_median_5'])\n",
        "\n",
        "etmColMayJune2019 = renameEtm_median_5(etmColMayJune2019)\n",
        "\n",
        "etmColJulyAug2019 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2019-07-01', '2019-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median') \\\n",
        "\n",
        "oliColJulyAug2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2019-07-01', '2019-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "JulyAug2019 = ee.ImageCollection([etmColJulyAug2019, oliColJulyAug2019])\n",
        "\n",
        "etmColJulyAug2019 = JulyAug2019.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_6(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median',  'NDVI_median_median'],\n",
        "      ['Blue_median_6', 'Green_median_6', 'Red_median_6', 'NIR_median_6','SWIR1_median_6', 'SWIR2_median_6', 'NDVI_median_6'])\n",
        "\n",
        "etmColJulyAug2019 = renameEtm_median_6(etmColJulyAug2019)\n",
        "\n",
        "\n",
        "##########\n",
        "## 2020 ##\n",
        "##########\n",
        "\n",
        "etmColMarchApril2020 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2020-03-01', '2020-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "oliColMarchApril2020 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2020-03-01', '2020-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "MarchApril2020 = ee.ImageCollection([etmColMarchApril2020, oliColMarchApril2020])\n",
        "\n",
        "etmColMarchApril2020 = MarchApril2020.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_7(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median',  'NDVI_median_median'],\n",
        "      ['Blue_median_7', 'Green_median_7', 'Red_median_7', 'NIR_median_7','SWIR1_median_7', 'SWIR2_median_7', 'NDVI_median_7'])\n",
        "\n",
        "etmColMarchApril2020 = renameEtm_median_7(etmColMarchApril2020)\n",
        "\n",
        "etmColMayJune2020 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2020-05-01', '2020-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "oliColMayJune2020 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2020-05-01', '2020-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "MayJune2020 = ee.ImageCollection([etmColMayJune2020, oliColMayJune2020])\n",
        "\n",
        "etmColMayJune2020 = MayJune2020.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_8(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median',  'NDVI_median_median'],\n",
        "      ['Blue_median_8', 'Green_median_8', 'Red_median_8', 'NIR_median_8','SWIR1_median_8', 'SWIR2_median_8', 'NDVI_median_8'])\n",
        "\n",
        "etmColMayJune2020 = renameEtm_median_8(etmColMayJune2020)\n",
        "\n",
        "etmColJulyAug2020 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2020-07-01', '2020-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median') \\\n",
        "\n",
        "oliColJulyAug2020 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2020-07-01', '2020-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('median')\n",
        "\n",
        "JulyAug2020 = ee.ImageCollection([etmColJulyAug2020, oliColJulyAug2020])\n",
        "\n",
        "etmColJulyAug2020 = JulyAug2020.reduce('median')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_median_9(img):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', 'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue_median_9', 'Green_median_9', 'Red_median_9', 'NIR_median_9','SWIR1_median_9', 'SWIR2_median_9',  'NDVI_median_9'])\n",
        "\n",
        "etmColJulyAug2020 = renameEtm_median_9(etmColJulyAug2020)\n",
        "\n",
        "#Combine images to one stack\n",
        "combinedImages = etmColMarchApril2018.addBands(etmColMayJune2018) \\\n",
        "  .addBands(etmColJulyAug2018) \\\n",
        "  .addBands(etmColMarchApril2019) \\\n",
        "  .addBands(etmColMayJune2019) \\\n",
        "  .addBands(etmColJulyAug2019) \\\n",
        "  .addBands(etmColMarchApril2020) \\\n",
        "  .addBands(etmColMayJune2020) \\\n",
        "  .addBands(etmColJulyAug2020) \\\n",
        "\n",
        "\n",
        "#combinedImages.getInfo()\n",
        "\n",
        "# Get a map ID for display in folium.\n",
        "rgb_vis = {'bands': ['Red_median_2', 'Green_median_2', 'Blue_median_2'], 'min': 0, 'max': 0.3, 'format': 'png'}\n",
        "mapid = combinedImages.getMapId(rgb_vis)\n",
        "\n",
        "# Turn into an array image for input to the model.\n",
        "array_image = combinedImages.float().toArray()\n",
        "\n",
        "\n",
        "#---- Normalizing the data per band (Do we want to normalize across years or within one year?)\n",
        "minMaxVal_file = '.'.join(out_model_file.split('.')[0:-1])\n",
        "minMaxVal_file = minMaxVal_file + '_minMax.txt'\n",
        "\n",
        "if not os.path.exists(minMaxVal_file): \n",
        "  min_per, max_per = readingsits.computingMinMax(X_train) #compute 98% min/max (per = 2) on bands\n",
        "  readingsits.save_minMaxVal(minMaxVal_file, min_per, max_per)\n",
        "else:\n",
        "  min_per, max_per = readingsits.read_minMaxVal(minMaxVal_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Point to the model hosted on AI Platform.  If you specified a region other\n",
        "# than the default (us-central1) at model creation, specify it here.\n",
        "model = ee.Model.fromAiPlatformPredictor(\n",
        "    projectName=PROJECT,\n",
        "    modelName=MODEL_NAME,\n",
        "    version=VERSION_NAME,\n",
        "    # Can be anything, but don't make it too big.\n",
        "    inputTileSize=[8, 8],\n",
        "    # Keep this the same as your training data.\n",
        "    proj=ee.Projection('EPSG:4326').atScale(30),\n",
        "    fixInputProj=True,\n",
        "    # Note the names here need to match what you specified in the\n",
        "    # output dictionary you passed to the EEifier.\n",
        "    outputBands={'output': {\n",
        "        'type': ee.PixelType.float(),\n",
        "        'dimensions': 1\n",
        "      }\n",
        "    },\n",
        ")\n",
        "\n",
        "inv_category_dict = {1:\"Open Water\", 2:\"Developed\", 3:\"Barren\", 4:\"Forest\", 5:\"Shrub\", 6:\"Grassland/Herbaceous\", 7:\"Pasture/CultivatedCrops\", 8:\"EmergentHerbWetlands\", 9:\"LeafySpurge\"} #define classes for prediction\n",
        "class_names = [inv_category_dict[i] for i in np.arange(1, 10)]\n",
        "\n",
        "import folium\n",
        "print(folium.__version__)\n",
        "\n",
        "# model.predictImage outputs a one dimensional array image that\n",
        "# packs the output nodes of your model into an array.  These\n",
        "# are class probabilities that you need to unpack into a \n",
        "# multiband image with arrayFlatten().  If you want class\n",
        "# labels, use arrayArgmax() as follows.\n",
        "predictions = model.predictImage(array_image)\n",
        "probabilities = predictions.arrayFlatten([class_names])\n",
        "label = predictions.arrayArgmax().arrayGet([0]).rename('label')\n",
        "\n",
        "\n",
        "probabilities.getInfo()\n",
        "\n",
        "# Get map IDs for display in folium.\n",
        "probability_vis = {\n",
        "    'bands': [\"Open Water\", \"Developed\", \"Barren\"], 'max': .5, 'format': 'png'\n",
        "}\n",
        "label_vis = {\n",
        "    'palette': ['red', 'green', 'blue'], 'min': 0, 'max': 2, 'format': 'png'\n",
        "}\n",
        "probability_mapid = probabilities.getMapId(probability_vis)\n",
        "label_mapid = label.getMapId(label_vis)\n",
        "\n",
        "# Visualize the input imagery and the predictions.\n",
        "map = folium.Map(location=[37.6413, -122.2582], zoom_start=11)\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=label_mapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='predicted label',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probability_mapid['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547r67GIO-4o",
        "outputId": "976d9682-915a-4b85-ce56-55e852ec964b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attempt': 1,\n",
              " 'creation_timestamp_ms': 1654026473124,\n",
              " 'description': 'clipped area',\n",
              " 'error_message': 'Export too large: specified 892227573612 pixels (max: 100000000). Specify higher maxPixels value if you intend to export a large area.',\n",
              " 'id': 'VEXJLYBH2ZLMYOI7FFL2LROU',\n",
              " 'name': 'projects/earthengine-legacy/operations/VEXJLYBH2ZLMYOI7FFL2LROU',\n",
              " 'start_timestamp_ms': 1654026485640,\n",
              " 'state': 'FAILED',\n",
              " 'task_type': 'EXPORT_IMAGE',\n",
              " 'update_timestamp_ms': 1654026487129}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1R_O5IeQO-62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model Performance"
      ],
      "metadata": {
        "id": "2g_WlRaTZoDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecH--JonxN-e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "This function prints and plots the confusion matrix.\n",
        "Normalization can be applied by setting `normalize=True`.\n",
        "y_true and y_pred are the ground truth and prediction, converted to vector with np.flatten()\n",
        "#Example Run\n",
        "y_pred = model.predict(X_val) #predict model on validation dataset\n",
        "y_pred = np.argmax(y_pred, axis=-1) #class with highest predicted probability is assigned to pixel\n",
        "y_pred_flat = y_pred.flatten() #flatten prediction to vector\n",
        "y_pred_flat = y_pred_flat.astype(int)\n",
        "y_val = Y_val.astype(int) #withheld validation dataset   \n",
        "y_val_flat = y_val.flatten()\n",
        "inv_category_dict = {1:\"Vegetation\", 2:\"Buildings\", 3:\"Roads\", 4:\"Water\", 5:\"Agriculture\", 6:\"Leafy Spurge\"} #define classes for prediction\n",
        "class_names = [inv_category_dict[i] for i in np.arange(1, 7)]\n",
        "# run function and save plot of normalized confusion matrix\n",
        "plot_confusion_matrix(\n",
        "    y_val_flat,\n",
        "    y_pred_flat,\n",
        "    classes=class_names,\n",
        "    test_name=model_name,\n",
        "    normalize=True,\n",
        "    save_fig=True\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "print(X_train.shape, y_train_one_hot.shape, X_val.shape, y_val_one_hot.shape, X_test.shape, y_test_one_hot.shape)\n",
        "\n",
        "\n",
        "#Example Run\n",
        "y_pred = model.predict(X_test) #predict model on validation dataset\n",
        "y_pred = np.argmax(y_pred, axis=-1) #class with highest predicted probability is assigned to pixel\n",
        "y_pred_flat = y_pred.flatten() #flatten prediction to vector\n",
        "y_pred_flat = y_pred_flat.astype(int)\n",
        "y_val = y_test.astype(int) #withheld validation dataset   \n",
        "y_val_flat = y_val.flatten()\n",
        "inv_category_dict = {1:\"Open Water\", 2:\"Developed\", 3:\"Barren\", 4:\"Forest\", 5:\"Shrub\", 6:\"Grassland/Herbaceous\", 7:\"Pasture/CultivatedCrops\", 8:\"EmergentHerbWetlands\", 9:\"LeafySpurge\"} #define classes for prediction\n",
        "class_names = [inv_category_dict[i] for i in np.arange(1, 10)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from skimage.io import imread, imshow, imsave\n",
        "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, cohen_kappa_score, accuracy_score, f1_score, precision_score, recall_score, jaccard_score, fbeta_score\n",
        "from tensorflow.keras.models import load_model\n",
        "from tabulate import tabulate\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        classes,\n",
        "        test_name,\n",
        "        normalize=False,\n",
        "        set_title=False,\n",
        "        cmap=plt.cm.Blues,\n",
        "):\n",
        "    \n",
        "    if set_title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    # and save it to log file\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    if normalize:\n",
        "        im.set_clim(0., 1.)     # fixes missing '1.0' tick at top of colorbar\n",
        "    cb = ax.figure.colorbar(im, ax=ax)\n",
        "    if normalize:\n",
        "        cb.set_ticks(np.arange(0., 1.2, 0.2))\n",
        "        cb.set_ticklabels([f'{i/5:.1f}' for i in range(6)])\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title if set_title else None,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "    ax.set_ylim(len(cm)-0.5, -0.5)\n",
        "    ax.xaxis.label.set_size(10)\n",
        "    ax.yaxis.label.set_size(10)\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            if np.round(cm[i, j], 2) > 0.:\n",
        "                ax.text(j, i, format(cm[i, j], fmt),\n",
        "                        ha=\"center\", va=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "            else:\n",
        "                ax.text(j, i, '–',\n",
        "                        ha=\"center\", va=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "\n",
        "# Interpret the confusion matrix\n",
        "# https://stackoverflow.com/questions/20927368/how-to-normalize-a-confusion-matrix\n",
        "cm = plot_confusion_matrix(y_val_flat, y_pred_flat, classes=class_names, normalize = True, test_name=\"test\") #how many samples per class have received their correct label (diagonal is recall/sensitivity value)\n",
        "\n",
        "\n",
        "C = confusion_matrix(y_val_flat, y_pred_flat)\n",
        "C / C.astype(np.float).sum(axis=1)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_val_flat, y_pred_flat)\n",
        "\n",
        "accuracy = accuracy_score(y_val_flat, y_pred_flat) #overall model accuracy\n",
        "\n",
        "print(precision, recall, fscore, support)\n",
        "\n",
        "\n",
        "#calculate confusion matrix\n",
        "class_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "c = multilabel_confusion_matrix(y_val_flat, y_pred_flat, labels = class_labels)\n",
        "model_output_metrics = []\n",
        "for i in range(len(class_labels)):\n",
        "    tn=c[i, 0, 0]\n",
        "    tp=c[i, 1, 1]\n",
        "    fn=c[i, 1, 0]\n",
        "    fp=c[i, 0, 1]\n",
        "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "    TPR_Sens_Recall = tp/(tp+fn)\n",
        "    TNR_Spec = tn/(tn+fp)\n",
        "    FPR = fp/(fp+tn)\n",
        "    FNR = fn/(fn+tp)\n",
        "    precision = tp/(tp+fp)\n",
        "    jaccard = tp/(tp+fp+fn)\n",
        "    beta = 0.5\n",
        "    F05 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
        "    beta = 1\n",
        "    F1 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
        "    beta = 2\n",
        "    F2 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
        "    outputs = [class_names[i], tp, tn, fp, fn, accuracy, TPR_Sens_Recall, TNR_Spec, FPR, FNR, precision, jaccard, F1]\n",
        "    model_output_metrics.append(outputs)\n",
        "print(tabulate(model_output_metrics, floatfmt=\".2f\", headers=[\"Class Name\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"TPR/Sens/Recall\", \"TNR/Spec\", \"FPR\", \"FNR\", \"Precision\", \"Jaccard\", \"F1\"]))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model predictions with Earth Engine and Tensorflow AI (now Vertex AI) platform"
      ],
      "metadata": {
        "id": "VYu4LTQ_MtxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puB5RsUIxOA0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1lmRgE8xOEK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj_AoraOtnNE"
      },
      "source": [
        "#Run Temporal CNN from command line Python\n",
        "\n",
        "(Not working currently)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQx74uVYg9Wu"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_test_path = \"/content/drive/My\\ Drive/Invasives\\ Research\\ UMN/Spurge\\ Remote\\ Sensing\\ Master/Leafy\\ Spurge\\ Demography/temporalCNN-master/example\"\n",
        "\n",
        "results_path = \"/content/drive/My\\ Drive/Invasives\\ Research\\ UMN/Spurge\\ Remote\\ Sensing\\ Master/Leafy\\ Spurge\\ Demography/results\"\n",
        "\n",
        "!python3 '/content/drive/My Drive/Invasives Research UMN/Spurge Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/run_archi.py' '--sits_path' {train_test_path} '--res_path' {results_path} '--noarchi' 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pehmshMhg9fn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzAWatDXg9iP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be5Af5omg9kY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8yYjHA2g9mb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Temporal CNN Leafy Spurge June 2022.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4mi3OZexzOnI2eFXuYPt8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}