{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temporal CNN Leafy Spurge Generate Training Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjUGv9Xb8KGRlUzK7MhkLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lake-thomas/spurge-temporal-cnn/blob/main/Temporal_CNN_Leafy_Spurge_Generate_Training_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This is a working Python notebook to implement Google Earth Engine <> TensorFlow for mapping invasive plant species from a time-series of Landsat imagery. In this example, the inputs are invasive species occurrence records from public databases. The model uses 1D-Conv layers in a temporal CNN framework."
      ],
      "metadata": {
        "id": "dYn8af1weyx4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J0voGyb2edNx"
      },
      "outputs": [],
      "source": [
        "# Cloud Authentication \n",
        "# Required When Using Default Google Cloud (i.e. Not Using a Hosted VM Runtime Environment)\n",
        "\n",
        "#Connect to hosted VM https://console.cloud.google.com/marketplace/product/colab-marketplace-image-public/colab?project=pacific-engine-346519\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n"
      ],
      "metadata": {
        "id": "xnkuanTgeldY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dbbba2-7f9b-4663-c86b-b95de43538cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=Pj-6MhdhQGcMf_JY8iIU60_9lLbNT-9rR7fO6LbFCaQ&tc=mgxjR-UVCgJZlE0Mbhi3Ik7A0WWkza9QC_p9QSeKb_g&cc=YHDXGeJcgDX2oy93m3OpPEAkUfTDHJLeM1s0c2Ch99A\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AX4XfWgABNTWzAgJyxiBq1cSHbvcn9QxpbTS-ujljU-bqq9sssFp8bhRlY4\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive for CSV reading\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Used to export to google cloud\n",
        "from google.cloud import storage\n",
        "import os\n",
        "\n",
        "# Only need this if you're running on GCE\n",
        "#os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'/content/drive/MyDrive/Colab Notebooks/pacific-engine-346519-8368a64310cd.json'\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55pWnkfGq-70",
        "outputId": "1555eb1c-b4b5-4a87-9f47-df464aafc806"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ignore Warnings and Errors\n",
        "!pip install geemap\n",
        "import geemap #advanced python function for GEE\n",
        "!pip install geopandas\n",
        "import geopandas #Pandas library to handle geospatial data\n",
        "!pip install fsspec\n",
        "import fsspec # file system specification\n",
        "!pip install gcsfs\n",
        "import gcsfs #google cloud file system"
      ],
      "metadata": {
        "id": "d8Y2tNbvelfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pprint\n",
        "import time\n",
        "from functools import reduce\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "2rQ6XADyelhz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow setup.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZjW4Nibeljy",
        "outputId": "e6d9147e-5ac4-4b6a-da01-95fa8e323f38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Functions\n",
        "Functions to process Landsat imagery"
      ],
      "metadata": {
        "id": "wYpLQ3pU_xA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to transfer feature properties to a dictionary.\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)\n",
        "\n",
        "\n",
        "#Cloud Mask: https://gis.stackexchange.com/questions/274048/apply-cloud-mask-to-landsat-imagery-in-google-earth-engine-python-api\n",
        "def getQABits(image, start, end, mascara): \n",
        "    # Compute the bits we need to extract.\n",
        "    pattern = 0\n",
        "    for i in range(start,end+1):\n",
        "        pattern += 2**i\n",
        "    # Return a single band image of the extracted QA bits, giving the     band a new name.\n",
        "    return image.select([0], [mascara]).bitwiseAnd(pattern).rightShift(start)\n",
        "\n",
        "\n",
        "#Saturated band Mask: https://gis.stackexchange.com/questions/363929/how-to-apply-a-bitmask-for-radiometric-saturation-qa-in-a-image-collection-eart\n",
        "def bitwiseExtract(value, fromBit, toBit):\n",
        "  maskSize = ee.Number(1).add(toBit).subtract(fromBit)\n",
        "  mask = ee.Number(1).leftShift(maskSize).subtract(1)\n",
        "  return value.rightShift(fromBit).bitwiseAnd(mask)\n",
        "\n",
        "\n",
        "#Function to mask out cloudy and saturated pixels and harmonize between Landsat 5/7/8 imagery \n",
        "def maskQuality(image):\n",
        "    # Select the QA band.\n",
        "    QA = image.select('QA_PIXEL')\n",
        "    # Get the internal_cloud_algorithm_flag bit.\n",
        "    sombra = getQABits(QA,3,3,'cloud_shadow')\n",
        "    nubes = getQABits(QA,5,5,'cloud')\n",
        "    #  var cloud_confidence = getQABits(QA,6,7,  'cloud_confidence')\n",
        "    cirrus_detected = getQABits(QA,9,9,'cirrus_detected')\n",
        "    #var cirrus_detected2 = getQABits(QA,8,8,  'cirrus_detected2')\n",
        "    #Return an image masking out cloudy areas.\n",
        "    QA_radsat = image.select('QA_RADSAT')\n",
        "    saturated = bitwiseExtract(QA_radsat, 1, 7)\n",
        "\n",
        "    #Apply the scaling factors to the appropriate bands.\n",
        "    def getFactorImg(factorNames):\n",
        "      factorList = image.toDictionary().select(factorNames).values()\n",
        "      return ee.Image.constant(factorList)\n",
        "\n",
        "    scaleImg = getFactorImg(['REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10'])\n",
        "\n",
        "    offsetImg = getFactorImg(['REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10'])\n",
        "    \n",
        "    scaled = image.select('SR_B.|ST_B10').multiply(scaleImg).add(offsetImg)\n",
        "\n",
        "    #Replace original bands with scaled bands and apply masks.\n",
        "    return image.addBands(scaled, None, True).updateMask(sombra.eq(0)).updateMask(nubes.eq(0).updateMask(cirrus_detected.eq(0).updateMask(saturated.eq(0))))\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for Landsat OLI.\n",
        "def renameOli(img):\n",
        "  return img.select(\n",
        "    ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL', 'QA_RADSAT'],\n",
        "    ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2', 'QA_PIXEL', 'QA_RADSAT'])\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm(img):\n",
        "  return img.select(\n",
        "    ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7', 'QA_PIXEL', 'QA_RADSAT'],\n",
        "    ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2', 'QA_PIXEL', 'QA_RADSAT'])\n",
        "\n",
        "\n",
        "# Adding a NDVI band\n",
        "def addNDVI(image):\n",
        "  ndvi = image.normalizedDifference(['NIR', 'Red']).rename('NDVI')\n",
        "  return image.addBands([ndvi])\n",
        "\n",
        "\n",
        "def mapDates(image):\n",
        "  date = ee.Date(image.get('system:time_start')).format(\"YYYY-MM-dd\")\n",
        "  return image.addBands([date])\n",
        "\n",
        "# Prepares (renames) OLI images.\n",
        "def prepOli(img):\n",
        "  img = renameOli(img)\n",
        "  return img\n",
        "\n",
        "\n",
        "# Prepares (renames) TM/ETM+ images.\n",
        "def prepEtm(img):\n",
        "  orig = img\n",
        "  img = renameEtm(img)\n",
        "  return ee.Image(img.copyProperties(orig, orig.propertyNames()))\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameImageBands_TM(img, year, season):\n",
        "  return img.select(\n",
        "      ['Blue_median', 'Green_median', 'Red_median', 'NIR_median', \n",
        "       'SWIR1_median', 'SWIR2_median', 'NDVI_median'],\n",
        "      ['Blue'+str(season)+str(year), 'Green'+str(season)+str(year), 'Red'+str(season)+str(year), 'NIR'+str(season)+str(year),\n",
        "       'SWIR1'+str(season)+str(year), 'SWIR2'+str(season)+str(year), 'NDVI'+str(season)+str(year)])\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameImageBands_ETMOLI(img, year, season):\n",
        "  return img.select(\n",
        "      ['Blue_median_median', 'Green_median_median', 'Red_median_median', 'NIR_median_median', \n",
        "       'SWIR1_median_median', 'SWIR2_median_median', 'NDVI_median_median'],\n",
        "      ['Blue'+str(season)+str(year), 'Green'+str(season)+str(year), 'Red'+str(season)+str(year), 'NIR'+str(season)+str(year),\n",
        "       'SWIR1'+str(season)+str(year), 'SWIR2'+str(season)+str(year), 'NDVI'+str(season)+str(year)])\n",
        "\n",
        "\n",
        "def getLandsatMosaicFromPoints(year, points):\n",
        "  '''\n",
        "  #Time-series extraction developed from\n",
        "  #https://developers.google.com/earth-engine/tutorials/community/time-series-visualization-with-altair#combine_dataframes  \n",
        "\n",
        "  '''\n",
        "\n",
        "  #if Year is between 1985 and 1999 use Landsat 5 TM imagery\n",
        "  if 1985 <= year <= 1999:\n",
        "\n",
        "    tmColMarchApril = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMarchApril = renameImageBands_TM(tmColMarchApril, year, 'MarchApril')\n",
        "\n",
        "    tmColMayJune = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMayJune = renameImageBands_TM(tmColMayJune, year, 'MayJune')\n",
        "\n",
        "    tmColJulyAug = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColJulyAug = renameImageBands_TM(tmColJulyAug, year, 'JulyAug')\n",
        "\n",
        "    landsat5ImageCol = [tmColMarchApril, tmColMayJune, tmColJulyAug]\n",
        "    return landsat5ImageCol\n",
        "\n",
        "  #if Year is between 2000 and 2012 use mosaic from Landsat 5 TM and Landsat 7 ETM imagery\n",
        "  elif 2000 <= year <= 2012:\n",
        "\n",
        "    etmColMarchApril = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMarchApril = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MarchApril = ee.ImageCollection([etmColMarchApril, tmColMarchApril])\n",
        "\n",
        "    etmColMarchApril = MarchApril.reduce('median')\n",
        "\n",
        "    etmColMarchApril = renameImageBands_ETMOLI(etmColMarchApril, year, 'MarchApril')\n",
        "\n",
        "    etmColMayJune = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMayJune = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MayJune = ee.ImageCollection([etmColMayJune, tmColMayJune])\n",
        "\n",
        "    etmColMayJune = MayJune.reduce('median')\n",
        "\n",
        "    etmColMayJune = renameImageBands_ETMOLI(etmColMayJune, year, 'MayJune')\n",
        "\n",
        "    etmColJulyAug = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColJulyAug = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    JulyAug = ee.ImageCollection([etmColJulyAug, tmColJulyAug])\n",
        "\n",
        "    etmColJulyAug = JulyAug.reduce('median')\n",
        "\n",
        "    etmColJulyAug = renameImageBands_ETMOLI(etmColJulyAug, year, 'JulyAug')\n",
        "\n",
        "    landsat5_7ImageCol = [etmColMarchApril, etmColMayJune, etmColJulyAug]\n",
        "    return landsat5_7ImageCol\n",
        "\n",
        "  #if Year is between 2013 and 2020 use mosaic from Landsat 7 ETM and Landsat 8 OLI imagery\n",
        "  elif 2013 <= year <= 2020:\n",
        "\n",
        "    etmColMarchApril = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    oliColMarchApril = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepOli) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MarchApril = ee.ImageCollection([etmColMarchApril, oliColMarchApril])\n",
        "\n",
        "    etmColMarchApril = MarchApril.reduce('median')\n",
        "\n",
        "    etmColMarchApril = renameImageBands_ETMOLI(etmColMarchApril, year, 'MarchApril')\n",
        "\n",
        "    etmColMayJune = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    oliColMayJune = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepOli) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MayJune = ee.ImageCollection([etmColMayJune, oliColMayJune])\n",
        "\n",
        "    etmColMayJune = MayJune.reduce('median')\n",
        "\n",
        "    etmColMayJune = renameImageBands_ETMOLI(etmColMayJune, year, 'MayJune')\n",
        "\n",
        "    etmColJulyAug = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median') \\\n",
        "\n",
        "    oliColJulyAug = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepOli) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    JulyAug = ee.ImageCollection([etmColJulyAug, oliColJulyAug])\n",
        "\n",
        "    etmColJulyAug = JulyAug.reduce('median')\n",
        "\n",
        "    etmColJulyAug = renameImageBands_ETMOLI(etmColJulyAug, year, 'JulyAug')\n",
        "\n",
        "    landsat7_8ImageCol = [etmColMarchApril, etmColMayJune, etmColJulyAug]\n",
        "\n",
        "    return landsat7_8ImageCol\n",
        "\n",
        "\n",
        "\n",
        "def sampleImagestoDataFrame(listofEEImages):\n",
        "    '''\n",
        "    Function takes in a list of three images from a Landsat imagery year (T1, T2, T3)\n",
        "    Returns a merged pandas dataframe of dimensions (rows/samples x bands) ordered from t-1, t, t+1\n",
        "    '''\n",
        "    image1 = listofEEImages[0]\n",
        "    image2 = listofEEImages[1]\n",
        "    image3 = listofEEImages[2]\n",
        "\n",
        "    image1_fc = image1.sampleRegions(collection=newpts, properties=['class'], scale=30)\n",
        "    image2_fc = image2.sampleRegions(collection=newpts, properties=['class'], scale=30)\n",
        "    image3_fc = image3.sampleRegions(collection=newpts, properties=['class'], scale=30)\n",
        "\n",
        "    image1_db_dict = fc_to_dict(image1_fc).getInfo()\n",
        "    image2_db_dict = fc_to_dict(image2_fc).getInfo()\n",
        "    image3_db_dict = fc_to_dict(image3_fc).getInfo()\n",
        "\n",
        "    image1_df = pd.DataFrame(image1_db_dict)\n",
        "    image2_df = pd.DataFrame(image2_db_dict)\n",
        "    image3_df = pd.DataFrame(image3_db_dict)\n",
        "\n",
        "    data_frames = [image1_df, image2_df, image3_df]\n",
        "\n",
        "    df_merged = reduce(lambda left,right: pd.merge(left, right, on='system:index', how='outer'), data_frames).fillna(np.nan)\n",
        "\n",
        "    df_merged_dropna = df_merged.dropna(axis=0, how = 'any')\n",
        "\n",
        "    return df_merged_dropna\n",
        "\n"
      ],
      "metadata": {
        "id": "jzovVIQN_reW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Bounding Box Moving Windows Across Study Region"
      ],
      "metadata": {
        "id": "UQSsRWGKOUjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Generate Bounding Box Coordinate List for Study Region ###\n",
        "#Starting position of bounding box\n",
        "XY_topLeft = [-116.976099, 48.904682]\n",
        "XY_topRight = [-115.976099, 48.904682]\n",
        "XY_bottomLeft = [-116.976099, 47.904682]\n",
        "XY_bottomRight = [-115.976099, 47.904682]\n",
        "\n",
        "lon_range = 31 #study area spans 31 deg lon\n",
        "lat_range = 12 #study area spans 12 deg lat\n",
        "\n",
        "stepSize = 1 #step by 1 degree of long/latitude\n",
        "\n",
        "\n",
        "def sliding_window(longitude_range, latitude_range, stepSize_box):\n",
        "    lon_list = []\n",
        "    lat_list = []\n",
        "    for lon in range(0, longitude_range, stepSize_box):\n",
        "      for lat in range(0, latitude_range,stepSize_box):\n",
        "        lon_list.append(lon)\n",
        "        lat_list.append(lat)\n",
        "    \n",
        "    return(lon_list, lat_list)\n",
        "\n",
        "def bbox(longitude_range, latitude_range, stepSize_box, topLeft_coord, topRight_coord, bottomLeft_coord, bottomRight_coord):\n",
        "  #Creates a sliding window across the lat/long range\n",
        "  #Returns a list of all lat/long boxes to sample \n",
        "     \n",
        "  lon_list, lat_list = sliding_window(longitude_range, latitude_range, stepSize_box) #Generates two lists: one of longitude[0-31] and one of latitude [0-12] defining study region\n",
        "\n",
        "  #for w in range(len(windows[0])):\n",
        "  #  w_lon = windows[0][w]\n",
        "  #  w_lat = windows[1][w]\n",
        "  #  #print(w_lon, w_lat)\n",
        "\n",
        "  #Top Left Coordinates for BBox\n",
        "  lon_list_X_topLeft = [x + topLeft_coord[0] for x in lon_list]\n",
        "  lat_list_Y_topLeft = [abs(x - topLeft_coord[1]) for x in lat_list]\n",
        "  XY_topLeft_list = list(zip(lon_list_X_topLeft, lat_list_Y_topLeft))\n",
        "\n",
        "  #Bottom Left Coordinates for BBox\n",
        "  lon_list_X_bottomLeft = [x + bottomLeft_coord[0] for x in lon_list]\n",
        "  lat_list_Y_bottomLeft = [abs(x - bottomLeft_coord[1]) for x in lat_list]\n",
        "  XY_bottomLeft_list = list(zip(lon_list_X_bottomLeft, lat_list_Y_bottomLeft))\n",
        "\n",
        "  #Top Right Coordinates for BBox\n",
        "  lon_list_X_topRight = [x + topRight_coord[0] for x in lon_list]\n",
        "  lat_list_Y_topRight = [abs(x - topRight_coord[1]) for x in lat_list]\n",
        "  XY_topRight_list = list(zip(lon_list_X_topRight, lat_list_Y_topRight))\n",
        "\n",
        "  #Bottom Right Coordinates for BBox\n",
        "  lon_list_X_bottomRight = [x + bottomRight_coord[0] for x in lon_list]\n",
        "  lat_list_Y_bottomRight = [abs(x - bottomRight_coord[1]) for x in lat_list]\n",
        "  XY_bottomRight_list = list(zip(lon_list_X_bottomRight, lat_list_Y_bottomRight))\n",
        "\n",
        "  ### Bounding Box Coordinate List\n",
        "  bbox = list(zip(XY_topLeft_list, XY_bottomLeft_list, XY_topRight_list, XY_bottomRight_list))\n",
        "\n",
        "  return bbox\n",
        "\n",
        "\n",
        "bbox_windows = bbox(lon_range, lat_range, stepSize, XY_topLeft, XY_topRight, XY_bottomLeft, XY_bottomRight)\n"
      ],
      "metadata": {
        "id": "g_90d9dDOG4k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Variables\n",
        "\n",
        "This is a set of global variables used throughout the notebook. You must have a Google Cloud Storage bucket into which you can write files. You'll also need to specify your Earth Engine username i.e. users/USER_NAME."
      ],
      "metadata": {
        "id": "MZMYPDxe_6ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define export for feature class assets\n",
        "OUTPUT_BUCKET = 'landcover_samples_nlcd2019_tfrecord_june2022'\n",
        "\n",
        "TRAIN_FILE_PREFIX = 'Training_nlcd2019'\n",
        "TEST_FILE_PREFIX = 'Testing_nlcd2019'\n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TEST_FILE_PREFIX + file_extension\n",
        "USER_NAME = 'lakex055'\n",
        "\n",
        "# File name for the prediction (image) dataset.  The trained model will read\n",
        "# this dataset and make predictions in each pixel.\n",
        "IMAGE_FILE_PREFIX = 'spurge_temporalcnn_demo_'\n",
        "\n",
        "# The output path for the classified image (i.e. predictions) TFRecord file.\n",
        "OUTPUT_IMAGE_FILE = 'gs://' + OUTPUT_BUCKET + '/spurge_temporalcnndemo.TFRecord'\n",
        "\n",
        "# The name of the Earth Engine asset to be created by importing\n",
        "# the classified image from the TFRecord file in Cloud Storage.\n",
        "OUTPUT_ASSET_ID = 'users/' + USER_NAME + '/spurge_temporalcnndemo'\n",
        "\n",
        "# Make sure the bucket exists.\n",
        "print('Found Cloud Storage bucket.' if tf.io.gfile.exists('gs://' + OUTPUT_BUCKET) \n",
        "  else 'Output Cloud Storage bucket does not exist.')\n",
        "\n",
        "\n",
        "BANDS = ['0_BlueMarchApril2018',\n",
        " '0_GreenMarchApril2018',\n",
        " '0_RedMarchApril2018',\n",
        " '0_NIRMarchApril2018',\n",
        " '0_SWIR1MarchApril2018',\n",
        " '0_SWIR2MarchApril2018',\n",
        " '0_NDVIMarchApril2018',\n",
        " '0_BlueMayJune2018',\n",
        " '0_GreenMayJune2018',\n",
        " '0_RedMayJune2018',\n",
        " '0_NIRMayJune2018',\n",
        " '0_SWIR1MayJune2018',\n",
        " '0_SWIR2MayJune2018',\n",
        " '0_NDVIMayJune2018',\n",
        " '0_BlueJulyAug2018',\n",
        " '0_GreenJulyAug2018',\n",
        " '0_RedJulyAug2018',\n",
        " '0_NIRJulyAug2018',\n",
        " '0_SWIR1JulyAug2018',\n",
        " '0_SWIR2JulyAug2018',\n",
        " '0_NDVIJulyAug2018',\n",
        " '1_BlueMarchApril2019',\n",
        " '1_GreenMarchApril2019',\n",
        " '1_RedMarchApril2019',\n",
        " '1_NIRMarchApril2019',\n",
        " '1_SWIR1MarchApril2019',\n",
        " '1_SWIR2MarchApril2019',\n",
        " '1_NDVIMarchApril2019',\n",
        " '1_BlueMayJune2019',\n",
        " '1_GreenMayJune2019',\n",
        " '1_RedMayJune2019',\n",
        " '1_NIRMayJune2019',\n",
        " '1_SWIR1MayJune2019',\n",
        " '1_SWIR2MayJune2019',\n",
        " '1_NDVIMayJune2019',\n",
        " '1_BlueJulyAug2019',\n",
        " '1_GreenJulyAug2019',\n",
        " '1_RedJulyAug2019',\n",
        " '1_NIRJulyAug2019',\n",
        " '1_SWIR1JulyAug2019',\n",
        " '1_SWIR2JulyAug2019',\n",
        " '1_NDVIJulyAug2019',\n",
        " '2_BlueMarchApril2020',\n",
        " '2_GreenMarchApril2020',\n",
        " '2_RedMarchApril2020',\n",
        " '2_NIRMarchApril2020',\n",
        " '2_SWIR1MarchApril2020',\n",
        " '2_SWIR2MarchApril2020',\n",
        " '2_NDVIMarchApril2020',\n",
        " '2_BlueMayJune2020',\n",
        " '2_GreenMayJune2020',\n",
        " '2_RedMayJune2020',\n",
        " '2_NIRMayJune2020',\n",
        " '2_SWIR1MayJune2020',\n",
        " '2_SWIR2MayJune2020',\n",
        " '2_NDVIMayJune2020',\n",
        " '2_BlueJulyAug2020',\n",
        " '2_GreenJulyAug2020',\n",
        " '2_RedJulyAug2020',\n",
        " '2_NIRJulyAug2020',\n",
        " '2_SWIR1JulyAug2020',\n",
        " '2_SWIR2JulyAug2020',\n",
        " '2_NDVIJulyAug2020']\n",
        "\n",
        "LABEL = 'class'\n",
        "\n",
        "# Number of label values, i.e. number of classes in the classification.\n",
        "N_CLASSES = 10\n",
        "\n",
        "# These names are used to specify properties in the export of\n",
        "# training/testing data and to define the mapping between names and data\n",
        "# when reading into TensorFlow datasets.\n",
        "FEATURE_NAMES = list(BANDS)\n",
        "FEATURE_NAMES.append(LABEL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UmP413bvhwj",
        "outputId": "f1a4c4ed-a7ea-44a7-c50c-5e92386cc313"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Cloud Storage bucket.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Workflow to Generate Training Datasets\n",
        "\n",
        "Iteratively generate bounding box arcross study area. Within each bounding box, extract points with labeled land cover values (including leafy spurge) and Landsat imagery. \n",
        "\n",
        "There are several limitations on the size and shape of Earth Engine table assets:\n",
        "\n",
        "Maximum of 100 million features\n",
        "\n",
        "Maximum of 1000 properties (columns)\n",
        "\n",
        "Maximum of 100,000 vertices for each row's geometry\n",
        "\n",
        "Maximum of 100,000 characters per string value\n"
      ],
      "metadata": {
        "id": "CD8GjxnjvnaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#define years to sample data (corresponds to satellite image year)\n",
        "years = [2018, 2019, 2020]\n",
        "\n",
        "#Training points for leafy spurge & land cover classes (defines extent of landsat imagery)\n",
        "\n",
        "#Load 1m training points sampled from 2019 NLCD and leafy spurge from 2018-2019-2020\n",
        "pts = ee.FeatureCollection('projects/pacific-engine-346519/assets/spurge_landcover_nlcd2019_onemillionpoints_april2022')\n",
        "\n",
        "#Moving Bounding Box Loop to Generate Sample Points\n",
        "for i in range(0, 2):\n",
        "#for i in range(3): testing only\n",
        "    \n",
        "  # Define Bounding Box\n",
        "  bbox = bbox_windows[i]\n",
        "  print(bbox)\n",
        "\n",
        "    # Filter points based on AOI\n",
        "  aoi = ee.Geometry.Polygon(bbox)\n",
        "\n",
        "  #Apply Filter\n",
        "  newpts = pts.filterBounds(aoi)\n",
        "\n",
        "  #How many points?\n",
        "  count = newpts.size() #returns an EE.Number object that we need to convert to an interger\n",
        "  num_points = int(count.getInfo())\n",
        "  print('Number of Points within AOI (Count): ', str(count.getInfo())+'\\n')\n",
        "\n",
        "  if num_points > 0:\n",
        "\n",
        "    # Sample imagery in a year filtered by input points\n",
        "    # Output is a list of length 3 EEimages, corresponding to three seasons in a year (e.g 2018: MarchApril, MayJune, JulyAug)\n",
        "    LandsatCol_year0 = getLandsatMosaicFromPoints(years[0], newpts)\n",
        "\n",
        "    LandsatCol_year1 = getLandsatMosaicFromPoints(years[1], newpts)\n",
        "    \n",
        "    LandsatCol_year2 = getLandsatMosaicFromPoints(years[2], newpts)\n",
        "\n",
        "    LandsatCol_timeseries = ee.ImageCollection([LandsatCol_year0, LandsatCol_year1, LandsatCol_year2])\n",
        "    \n",
        "    LandsatCol_timeseries_image = LandsatCol_timeseries.toBands()\n",
        "    #LandsatCol_timeseries_image.bandNames().getInfo()\n",
        "\n",
        "    # Sample the image at the points and add a random column.\n",
        "    sample = LandsatCol_timeseries_image.sampleRegions(collection=newpts, properties=['class'], scale=30).randomColumn()\n",
        "\n",
        "    # Partition the sample approximately 70-30.\n",
        "    training = sample.filter(ee.Filter.lt('random', 0.2)) #lt 0.7\n",
        "    testing = sample.filter(ee.Filter.gt('random', 0.8)) #gte 0.3\n",
        "\n",
        "    count = training.size() #returns an EE.Number object that we need to convert to an interger\n",
        "    num_points = int(count.getInfo())\n",
        "    print('Number of Points within AOI (Count): ', str(count.getInfo())+'\\n')\n",
        "\n",
        "    #from pprint import pprint\n",
        "\n",
        "    # Print the first couple points to verify.\n",
        "    #pprint({'training': training.first().getInfo()})\n",
        "    #pprint({'testing': testing.first().getInfo()})\n",
        "\n",
        "        \n",
        "    # Create the tasks.\n",
        "    training_task = ee.batch.Export.table.toCloudStorage(\n",
        "      collection=training,\n",
        "      description='Training Export',\n",
        "      fileNamePrefix=TRAIN_FILE_PREFIX + \"_\" + str(i),\n",
        "      bucket=OUTPUT_BUCKET,\n",
        "      fileFormat='TFRecord',\n",
        "      selectors=FEATURE_NAMES)\n",
        "\n",
        "    testing_task = ee.batch.Export.table.toCloudStorage(\n",
        "      collection=testing,\n",
        "      description='Testing Export',\n",
        "      fileNamePrefix=TEST_FILE_PREFIX + \"_\" + str(i),\n",
        "      bucket=OUTPUT_BUCKET,\n",
        "      fileFormat='TFRecord',\n",
        "      selectors=FEATURE_NAMES)\n",
        "\n",
        "    # Start the tasks.\n",
        "    training_task.start()\n",
        "    testing_task.start()\n",
        "\n",
        "    # Export imagery in this region.\n",
        "    EXPORT_REGION = aoi\n",
        "\n",
        "    # Specify patch and file dimensions.\n",
        "    image_export_options = {\n",
        "      'patchDimensions': [512, 512],\n",
        "      'maxFileSize': 104857600,\n",
        "      'compressed': True\n",
        "    }\n",
        "\n",
        "    # Setup the task.\n",
        "    image_task = ee.batch.Export.image.toCloudStorage(\n",
        "      image=LandsatCol_timeseries_image,\n",
        "      description='Image Export',\n",
        "      fileNamePrefix=IMAGE_FILE_PREFIX + \"_\" + str(i),\n",
        "      bucket=OUTPUT_BUCKET,\n",
        "      scale=30,\n",
        "      fileFormat='TFRecord',\n",
        "      region=EXPORT_REGION.toGeoJSON()['coordinates'],\n",
        "      formatOptions=image_export_options,\n",
        "    )\n",
        "\n",
        "    # Start the task.\n",
        "    image_task.start()\n",
        "\n",
        "    #Wait for export tasks to finish\n",
        "\n",
        "    while image_task.active():\n",
        "      print('Polling for image task (state: {}).'.format(ee.data.getTaskStatus(image_task.id)[0].get('state')))\n",
        "      print('Polling for training (id: {}).'.format(ee.data.getTaskStatus(training_task.id)[0].get('state')))\n",
        "      print('Polling for testing (id: {}).'.format(ee.data.getTaskStatus(testing_task.id)[0].get('state')))\n",
        "      time.sleep(15)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "IJyKw53yelmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75af9d52-6e86-4423-8860-547ad1632a68"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n",
            "Polling for image task (state: RUNNING).\n",
            "Polling for training (id: COMPLETED).\n",
            "Polling for testing (id: COMPLETED).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation and pre-processing\n",
        "\n",
        "Read data from the TFRecord file into a `tf.data.Dataset`.  Pre-process the dataset to get it into a suitable format for input to the model.\n",
        "\n",
        "## Read into a `tf.data.Dataset`\n",
        "\n",
        "Here we are going to read a file in Cloud Storage into a `tf.data.Dataset`.  ([these TensorFlow docs](https://www.tensorflow.org/guide/data) explain more about reading data into a `Dataset`).  Check that you can read examples from the file.  The purpose here is to ensure that we can read from the file without an error.  The actual content is not necessarily human readable.\n"
      ],
      "metadata": {
        "id": "2wF6kMjj4nGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
        "# Print the first record to check.\n",
        "print(iter(train_dataset).next())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g--EDJEV4h7S",
        "outputId": "716870ae-e371-44e0-ee08-417360eb4d0f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'\\n\\xfc\\x0f\\n \\n\\x140_BlueMarchApril2018\\x12\\x08\\x12\\x06\\n\\x04\\x15W\\x05=\\n!\\n\\x150_GreenMarchApril2018\\x12\\x08\\x12\\x06\\n\\x04_$4=\\n\\x1f\\n\\x130_RedMarchApril2018\\x12\\x08\\x12\\x06\\n\\x04\\t\\x16\\x07=\\n\\x1f\\n\\x130_NIRMarchApril2018\\x12\\x08\\x12\\x06\\n\\x04j\\xa4\\xa5<\\n!\\n\\x150_SWIR1MarchApril2018\\x12\\x08\\x12\\x06\\n\\x04\\xc5\\xac\\x97<\\n!\\n\\x150_SWIR2MarchApril2018\\x12\\x08\\x12\\x06\\n\\x04\\xc9v~<\\n \\n\\x140_NDVIMarchApril2018\\x12\\x08\\x12\\x06\\n\\x04c\\xf7`\\xbe\\n\\x1d\\n\\x110_BlueMayJune2018\\x12\\x08\\x12\\x06\\n\\x04j\\xfb\\xf7<\\n\\x1e\\n\\x120_GreenMayJune2018\\x12\\x08\\x12\\x06\\n\\x04\\xb4<?=\\n\\x1c\\n\\x100_RedMayJune2018\\x12\\x08\\x12\\x06\\n\\x04\\xff\\x95\\x1d=\\n\\x1c\\n\\x100_NIRMayJune2018\\x12\\x08\\x12\\x06\\n\\x04\\x83\\xc0\\xda<\\n\\x1e\\n\\x120_SWIR1MayJune2018\\x12\\x08\\x12\\x06\\n\\x04=D\\xc3<\\n\\x1e\\n\\x120_SWIR2MayJune2018\\x12\\x08\\x12\\x06\\n\\x04\\xeew\\x88<\\n\\x1d\\n\\x110_NDVIMayJune2018\\x12\\x08\\x12\\x06\\n\\x04YR+\\xbe\\n\\x1d\\n\\x110_BlueJulyAug2018\\x12\\x08\\x12\\x06\\n\\x04^\\x11\\x14=\\n\\x1e\\n\\x120_GreenJulyAug2018\\x12\\x08\\x12\\x06\\n\\x04\\xd5x!=\\n\\x1c\\n\\x100_RedJulyAug2018\\x12\\x08\\x12\\x06\\n\\x04\\x9fv\\x10=\\n\\x1c\\n\\x100_NIRJulyAug2018\\x12\\x08\\x12\\x06\\n\\x04\\x85\\xb6\\x1c=\\n\\x1e\\n\\x120_SWIR1JulyAug2018\\x12\\x08\\x12\\x06\\n\\x04\\x8b\\xc3\\x01=\\n\\x1e\\n\\x120_SWIR2JulyAug2018\\x12\\x08\\x12\\x06\\n\\x04}\\x05\\xa9<\\n\\x1d\\n\\x110_NDVIJulyAug2018\\x12\\x08\\x12\\x06\\n\\x04D\\xed\\x82=\\n \\n\\x141_BlueMarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\x86UD=\\n!\\n\\x151_GreenMarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\xb9\\x19^=\\n\\x1f\\n\\x131_RedMarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\xbb\\xb8-=\\n\\x1f\\n\\x131_NIRMarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\xd5\\t\\xf8<\\n!\\n\\x151_SWIR1MarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\xcff\\xd5<\\n!\\n\\x151_SWIR2MarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\x15R\\x9e<\\n \\n\\x141_NDVIMarchApril2019\\x12\\x08\\x12\\x06\\n\\x04\\xbc\\xc3\\x8f\\xbe\\n\\x1d\\n\\x111_BlueMayJune2019\\x12\\x08\\x12\\x06\\n\\x04m\\xff\\x12=\\n\\x1e\\n\\x121_GreenMayJune2019\\x12\\x08\\x12\\x06\\n\\x04\\xa1-G=\\n\\x1c\\n\\x101_RedMayJune2019\\x12\\x08\\x12\\x06\\n\\x04\\x0b\\x0c)=\\n\\x1c\\n\\x101_NIRMayJune2019\\x12\\x08\\x12\\x06\\n\\x04\\x9e$\\x05=\\n\\x1e\\n\\x121_SWIR1MayJune2019\\x12\\x08\\x12\\x06\\n\\x04;S\\xe8<\\n\\x1e\\n\\x121_SWIR2MayJune2019\\x12\\x08\\x12\\x06\\n\\x04\\xf91\\xc6<\\n\\x1d\\n\\x111_NDVIMayJune2019\\x12\\x08\\x12\\x06\\n\\x04k\\x91\\x86\\xbd\\n\\x1d\\n\\x111_BlueJulyAug2019\\x12\\x08\\x12\\x06\\n\\x04\\x19\\x90\\r=\\n\\x1e\\n\\x121_GreenJulyAug2019\\x12\\x08\\x12\\x06\\n\\x04v\\xa60=\\n\\x1c\\n\\x101_RedJulyAug2019\\x12\\x08\\x12\\x06\\n\\x04\\x1d\\x8f\\x19=\\n\\x1c\\n\\x101_NIRJulyAug2019\\x12\\x08\\x12\\x06\\n\\x04\\xb5TN=\\n\\x1e\\n\\x121_SWIR1JulyAug2019\\x12\\x08\\x12\\x06\\n\\x04\\xf2\\xb0\\x08=\\n\\x1e\\n\\x121_SWIR2JulyAug2019\\x12\\x08\\x12\\x06\\n\\x04\\xa90\\xd6<\\n\\x1d\\n\\x111_NDVIJulyAug2019\\x12\\x08\\x12\\x06\\n\\x04Zp\\x1b>\\n \\n\\x142_BlueMarchApril2020\\x12\\x08\\x12\\x06\\n\\x04xz\\r=\\n!\\n\\x152_GreenMarchApril2020\\x12\\x08\\x12\\x06\\n\\x04\\x1b\\xd8:=\\n\\x1f\\n\\x132_RedMarchApril2020\\x12\\x08\\x12\\x06\\n\\x04\\x02\\x0e\\x11=\\n\\x1f\\n\\x132_NIRMarchApril2020\\x12\\x08\\x12\\x06\\n\\x04\\xc8^\\xdf<\\n!\\n\\x152_SWIR1MarchApril2020\\x12\\x08\\x12\\x06\\n\\x04\\xacs\\xbc<\\n!\\n\\x152_SWIR2MarchApril2020\\x12\\x08\\x12\\x06\\n\\x04u\\xcd\\x94<\\n \\n\\x142_NDVIMarchApril2020\\x12\\x08\\x12\\x06\\n\\x04E94\\xbe\\n\\x1d\\n\\x112_BlueMayJune2020\\x12\\x08\\x12\\x06\\n\\x04\\xc3G\\xc4<\\n\\x1e\\n\\x122_GreenMayJune2020\\x12\\x08\\x12\\x06\\n\\x04\\xd1\"\\x1b=\\n\\x1c\\n\\x102_RedMayJune2020\\x12\\x08\\x12\\x06\\n\\x04y]\\x0f=\\n\\x1c\\n\\x102_NIRMayJune2020\\x12\\x08\\x12\\x06\\n\\x04\\xc8\\x0c\\xd4<\\n\\x1e\\n\\x122_SWIR1MayJune2020\\x12\\x08\\x12\\x06\\n\\x042\\x03U<\\n\\x1e\\n\\x122_SWIR2MayJune2020\\x12\\x08\\x12\\x06\\n\\x04xEp<\\n\\x1d\\n\\x112_NDVIMayJune2020\\x12\\x08\\x12\\x06\\n\\x04@\\x84I\\xbe\\n\\x1d\\n\\x112_BlueJulyAug2020\\x12\\x08\\x12\\x06\\n\\x04\\xf8\\x8d\\xaf<\\n\\x1e\\n\\x122_GreenJulyAug2020\\x12\\x08\\x12\\x06\\n\\x04\\xbe\\x87\\xfb<\\n\\x1c\\n\\x102_RedJulyAug2020\\x12\\x08\\x12\\x06\\n\\x04c\\xb4\\xbe<\\n\\x1c\\n\\x102_NIRJulyAug2020\\x12\\x08\\x12\\x06\\n\\x04$\\xee\\t=\\n\\x1e\\n\\x122_SWIR1JulyAug2020\\x12\\x08\\x12\\x06\\n\\x04\\x1c\\x99\\xd7<\\n\\x1e\\n\\x122_SWIR2JulyAug2020\\x12\\x08\\x12\\x06\\n\\x04\\xae\\xb6\\xa2<\\n\\x1d\\n\\x112_NDVIJulyAug2020\\x12\\x08\\x12\\x06\\n\\x04\\xebl\">\\n\\x11\\n\\x05class\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x80?', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the structure of your data\n",
        "\n",
        "For parsing the exported TFRecord files, `featuresDict` is a mapping between feature names (recall that `featureNames` contains the band and label names) and `float32` [`tf.io.FixedLenFeature`](https://www.tensorflow.org/api_docs/python/tf/io/FixedLenFeature) objects.  This mapping is necessary for telling TensorFlow how to read data in a TFRecord file into tensors.  Specifically, **all numeric data exported from Earth Engine is exported as `float32`**.\n",
        "\n",
        "(Note: *features* in the TensorFlow context (i.e. [`tf.train.Feature`](https://www.tensorflow.org/api_docs/python/tf/train/Feature)) are not to be confused with Earth Engine features (i.e. [`ee.Feature`](https://developers.google.com/earth-engine/api_docs#eefeature)), where the former is a protocol message type for serialized data input to the model and the latter is a geometry-based geographic data structure.)"
      ],
      "metadata": {
        "id": "J0ahuFhb4oHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
        "\n",
        "pprint(features_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4k8UMo34h9h",
        "outputId": "d31c175b-0d82-4def-8cde-ac5b0fd853d7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0_BlueJulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_BlueMarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_BlueMayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_GreenJulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_GreenMarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_GreenMayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_NDVIJulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_NDVIMarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_NDVIMayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_NIRJulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_NIRMarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_NIRMayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_RedJulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_RedMarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_RedMayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_SWIR1JulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_SWIR1MarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_SWIR1MayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_SWIR2JulyAug2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_SWIR2MarchApril2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '0_SWIR2MayJune2018': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_BlueJulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_BlueMarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_BlueMayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_GreenJulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_GreenMarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_GreenMayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_NDVIJulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_NDVIMarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_NDVIMayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_NIRJulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_NIRMarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_NIRMayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_RedJulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_RedMarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_RedMayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_SWIR1JulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_SWIR1MarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_SWIR1MayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_SWIR2JulyAug2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_SWIR2MarchApril2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '1_SWIR2MayJune2019': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_BlueJulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_BlueMarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_BlueMayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_GreenJulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_GreenMarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_GreenMayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_NDVIJulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_NDVIMarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_NDVIMayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_NIRJulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_NIRMarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_NIRMayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_RedJulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_RedMarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_RedMayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_SWIR1JulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_SWIR1MarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_SWIR1MayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_SWIR2JulyAug2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_SWIR2MarchApril2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " '2_SWIR2MayJune2020': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
            " 'class': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse the dataset\n",
        "\n",
        "Now we need to make a parsing function for the data in the TFRecord files.  The data comes in flattened 2D arrays per record and we want to use the first part of the array for input to the model and the last element of the array as the class label.  The parsing function reads data from a serialized [`Example` proto](https://www.tensorflow.org/api_docs/python/tf/train/Example) into a dictionary in which the keys are the feature names and the values are the tensors storing the value of the features for that example.  ([These TensorFlow docs](https://www.tensorflow.org/tutorials/load_data/tfrecord) explain more about reading `Example` protos from TFRecord files).\n",
        "\n",
        "Note that each record of the parsed dataset contains a tuple.  The first element of the tuple is a dictionary with bands for keys and the numeric value of the bands for values.  The second element of the tuple is a class label."
      ],
      "metadata": {
        "id": "0zoTxyTt4nz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by featuresDict.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "pprint(iter(parsed_dataset).next())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkjNGX0A4h_6",
        "outputId": "96384d3c-109c-4200-8365-54d3ed1fc1fe"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'0_BlueJulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03614938], dtype=float32)>,\n",
            "  '0_BlueMarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03255375], dtype=float32)>,\n",
            "  '0_BlueMayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03027125], dtype=float32)>,\n",
            "  '0_GreenJulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03942188], dtype=float32)>,\n",
            "  '0_GreenMarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04398], dtype=float32)>,\n",
            "  '0_GreenMayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04668875], dtype=float32)>,\n",
            "  '0_NDVIJulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06392911], dtype=float32)>,\n",
            "  '0_NDVIMarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.2196937], dtype=float32)>,\n",
            "  '0_NDVIMayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.16730632], dtype=float32)>,\n",
            "  '0_NIRJulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03826], dtype=float32)>,\n",
            "  '0_NIRMarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02022], dtype=float32)>,\n",
            "  '0_NIRMayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02670312], dtype=float32)>,\n",
            "  '0_RedJulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03526938], dtype=float32)>,\n",
            "  '0_RedMarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03298], dtype=float32)>,\n",
            "  '0_RedMayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03847313], dtype=float32)>,\n",
            "  '0_SWIR1JulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03168062], dtype=float32)>,\n",
            "  '0_SWIR1MarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.018515], dtype=float32)>,\n",
            "  '0_SWIR1MayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02383625], dtype=float32)>,\n",
            "  '0_SWIR2JulyAug2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0206325], dtype=float32)>,\n",
            "  '0_SWIR2MarchApril2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01553125], dtype=float32)>,\n",
            "  '0_SWIR2MayJune2018': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01665875], dtype=float32)>,\n",
            "  '1_BlueJulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03456125], dtype=float32)>,\n",
            "  '1_BlueMarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04793312], dtype=float32)>,\n",
            "  '1_BlueMayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03588812], dtype=float32)>,\n",
            "  '1_GreenJulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0431275], dtype=float32)>,\n",
            "  '1_GreenMarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.05422375], dtype=float32)>,\n",
            "  '1_GreenMayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0486275], dtype=float32)>,\n",
            "  '1_NDVIJulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.15179577], dtype=float32)>,\n",
            "  '1_NDVIMarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.2807902], dtype=float32)>,\n",
            "  '1_NDVIMayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.06570705], dtype=float32)>,\n",
            "  '1_NIRJulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.05037375], dtype=float32)>,\n",
            "  '1_NIRMarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03027813], dtype=float32)>,\n",
            "  '1_NIRMayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03250562], dtype=float32)>,\n",
            "  '1_RedJulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03749], dtype=float32)>,\n",
            "  '1_RedMarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0424125], dtype=float32)>,\n",
            "  '1_RedMayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04127125], dtype=float32)>,\n",
            "  '1_SWIR1JulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03337187], dtype=float32)>,\n",
            "  '1_SWIR1MarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02605], dtype=float32)>,\n",
            "  '1_SWIR1MayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02836], dtype=float32)>,\n",
            "  '1_SWIR2JulyAug2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02614625], dtype=float32)>,\n",
            "  '1_SWIR2MarchApril2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01932625], dtype=float32)>,\n",
            "  '1_SWIR2MayJune2019': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02419375], dtype=float32)>,\n",
            "  '2_BlueJulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02143], dtype=float32)>,\n",
            "  '2_BlueMarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03454062], dtype=float32)>,\n",
            "  '2_BlueMayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02396], dtype=float32)>,\n",
            "  '2_GreenJulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03070438], dtype=float32)>,\n",
            "  '2_GreenMarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04561625], dtype=float32)>,\n",
            "  '2_GreenMayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.037875], dtype=float32)>,\n",
            "  '2_NDVIJulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.15861861], dtype=float32)>,\n",
            "  '2_NDVIMarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.17599972], dtype=float32)>,\n",
            "  '2_NDVIMayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-0.19679356], dtype=float32)>,\n",
            "  '2_NIRJulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03367437], dtype=float32)>,\n",
            "  '2_NIRMarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02726687], dtype=float32)>,\n",
            "  '2_NIRMayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.025885], dtype=float32)>,\n",
            "  '2_RedJulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02327937], dtype=float32)>,\n",
            "  '2_RedMarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03541375], dtype=float32)>,\n",
            "  '2_RedMayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.03500125], dtype=float32)>,\n",
            "  '2_SWIR1JulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02631813], dtype=float32)>,\n",
            "  '2_SWIR1MarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.02300438], dtype=float32)>,\n",
            "  '2_SWIR1MayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01300125], dtype=float32)>,\n",
            "  '2_SWIR2JulyAug2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0198625], dtype=float32)>,\n",
            "  '2_SWIR2MarchApril2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01816438], dtype=float32)>,\n",
            "  '2_SWIR2MayJune2020': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.014665], dtype=float32)>},\n",
            " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Keras model\n",
        "\n",
        "Before we create the model, there's still a wee bit of pre-processing to get the data into the right input shape and a format that can be used with cross-entropy loss.  Specifically, Keras expects a list of inputs and a one-hot vector for the class. (See [the Keras loss function docs](https://keras.io/losses/), [the TensorFlow categorical identity docs](https://www.tensorflow.org/guide/feature_columns#categorical_identity_column) and [the `tf.one_hot` docs](https://www.tensorflow.org/api_docs/python/tf/one_hot) for details).  \n",
        "\n",
        "Here we will use a simple neural network model with a 64 node hidden layer, a dropout layer and an output layer.  Once the dataset has been prepared, define the model, compile it, fit it to the training data.  See [the Keras `Sequential` model guide](https://keras.io/getting-started/sequential-model-guide/) for more details."
      ],
      "metadata": {
        "id": "coiDbBKL4obk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Keras requires inputs as a tuple.  Note that the inputs must be in the\n",
        "# right shape.  Also note that to use the categorical_crossentropy loss,\n",
        "# the label needs to be turned into a one-hot vector.\n",
        "def to_tuple(inputs, label):\n",
        "  return (tf.transpose(list(inputs.values())),\n",
        "          tf.one_hot(indices=label, depth=N_CLASSES))\n",
        "\n",
        "# Map the to_tuple function, shuffle and batch.\n",
        "input_dataset = parsed_dataset.map(to_tuple).batch(8)\n",
        "\n",
        "# Define the layers in the model.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model with the specified loss function.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to the training data.\n",
        "model.fit(x=input_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WNSyOOR4iCR",
        "outputId": "bf346bff-92b4-4551-d2d8-f0320c8af876"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "148/148 [==============================] - 2s 5ms/step - loss: 2.1079 - accuracy: 0.3401\n",
            "Epoch 2/10\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1.5958 - accuracy: 0.3995\n",
            "Epoch 3/10\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 1.4706 - accuracy: 0.4427\n",
            "Epoch 4/10\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1.4546 - accuracy: 0.4538\n",
            "Epoch 5/10\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 1.3107 - accuracy: 0.4809\n",
            "Epoch 6/10\n",
            "148/148 [==============================] - 1s 6ms/step - loss: 1.2906 - accuracy: 0.5089\n",
            "Epoch 7/10\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1.3035 - accuracy: 0.5064\n",
            "Epoch 8/10\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1.2637 - accuracy: 0.5038\n",
            "Epoch 9/10\n",
            "148/148 [==============================] - 1s 5ms/step - loss: 1.2168 - accuracy: 0.5318\n",
            "Epoch 10/10\n",
            "148/148 [==============================] - 1s 4ms/step - loss: 1.1800 - accuracy: 0.5462\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a4cf81510>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check model accuracy on the test set\n",
        "\n",
        "Now that we have a trained model, we can evaluate it using the test dataset.  To do that, read and prepare the test dataset in the same way as the training dataset.  Here we specify a batch size of 1 so that each example in the test set is used exactly once to compute model accuracy.  For model steps, just specify a number larger than the test dataset size (ignore the warning)."
      ],
      "metadata": {
        "id": "ekMl3v__4orO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = (\n",
        "  tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(to_tuple)\n",
        "    .batch(1))\n",
        "\n",
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-tiVFEX4iEm",
        "outputId": "1f5764db-234e-4c29-e76a-5a329803e65f"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1157/1157 [==============================] - 6s 4ms/step - loss: 1.2486 - accuracy: 0.5583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2486305236816406, 0.5583405494689941]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the trained model to classify an image from Earth Engine\n",
        "\n",
        "Now it's time to classify the image that was exported from Earth Engine.  If the exported image is large, it will be split into multiple TFRecord files in its destination folder.  There will also be a JSON sidecar file called \"the mixer\" that describes the format and georeferencing of the image.  Here we will find the image files and the mixer file, getting some info out of the mixer that will be useful during model inference.\n",
        "\n",
        "## Find the image files and JSON mixer file in Cloud Storage\n",
        "\n",
        "Use `gsutil` to locate the files of interest in the output Cloud Storage bucket.  Check to make sure your image export task finished before running the following."
      ],
      "metadata": {
        "id": "vHAR5Z_95ToX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the files in the output bucket.\n",
        "files_list = !gsutil ls 'gs://'{OUTPUT_BUCKET}\n",
        "# Get only the files generated by the image export.\n",
        "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n",
        "\n",
        "# Get the list of image files and the JSON mixer file.\n",
        "image_files_list = []\n",
        "json_file = None\n",
        "for f in exported_files_list:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    image_files_list.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    json_file = f\n",
        "\n",
        "# Make sure the files are in the right order.\n",
        "image_files_list.sort()\n",
        "\n",
        "pprint(image_files_list)\n",
        "print(json_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g343BAv4iGn",
        "outputId": "cafe19f8-1733-44cd-ae6e-a360bbeba54a"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00000.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00001.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00002.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00003.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00004.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00005.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00006.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00007.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00008.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00009.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00010.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00011.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00012.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00013.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00014.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00015.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00016.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00017.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00018.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00019.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00020.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00021.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00022.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00023.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00024.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00025.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00026.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00027.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00028.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00029.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00030.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00031.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00032.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00033.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00034.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00035.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00036.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00037.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00038.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00039.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00040.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00041.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00042.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00043.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00044.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00045.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00046.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00047.tfrecord.gz',\n",
            " 'gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_00048.tfrecord.gz']\n",
            "gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnn_demo_mixer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the JSON mixer file\n",
        "\n",
        "The mixer contains metadata and georeferencing information for the exported patches, each of which is in a different file.  Read the mixer to get some information needed for prediction."
      ],
      "metadata": {
        "id": "cnPvW1-Z5UPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the contents of the mixer file to a JSON object.\n",
        "json_text = !gsutil cat {json_file}\n",
        "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "mixer = json.loads(json_text.nlstr)\n",
        "pprint(mixer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IjUfsrc4iI_",
        "outputId": "6292cb09-b190-441f-9cbb-6f0aa62ef36b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'patchDimensions': [512, 512],\n",
            " 'patchesPerRow': 7,\n",
            " 'projection': {'affine': {'doubleMatrix': [0.00026949458523585647,\n",
            "                                            0.0,\n",
            "                                            -116.97628067830539,\n",
            "                                            0.0,\n",
            "                                            -0.00026949458523585647,\n",
            "                                            47.904818482355374]},\n",
            "                'crs': 'EPSG:4326'},\n",
            " 'totalPatches': 49}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the image files into a dataset\n",
        "\n",
        "You can feed the list of files (`imageFilesList`) directly to the `TFRecordDataset` constructor to make a combined dataset on which to perform inference.  The input needs to be preprocessed differently than the training and testing.  Mainly, this is because the pixels are written into records as patches, we need to read the patches in as one big tensor (one patch for each band), then flatten them into lots of little tensors."
      ],
      "metadata": {
        "id": "4N5Xx3hX5Ujq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get relevant info from the JSON mixer file.\n",
        "patch_width = mixer['patchDimensions'][0]\n",
        "patch_height = mixer['patchDimensions'][1]\n",
        "patches = mixer['totalPatches']\n",
        "patch_dimensions_flat = [patch_width * patch_height, 1]\n",
        "\n",
        "# Note that the tensors are in the shape of a patch, one patch for each band.\n",
        "image_columns = [\n",
        "  tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) \n",
        "    for k in BANDS\n",
        "]\n",
        "\n",
        "# Parsing dictionary.\n",
        "image_features_dict = dict(zip(BANDS, image_columns))\n",
        "\n",
        "# Note that you can make one dataset from many files by specifying a list.\n",
        "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
        "\n",
        "# Parsing function.\n",
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, image_features_dict)\n",
        "\n",
        "# Parse the data into tensors, one long tensor per patch.\n",
        "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
        "\n",
        "# Break our long tensors into many little ones.\n",
        "image_dataset = image_dataset.flat_map(\n",
        "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
        ")\n",
        "\n",
        "# Turn the dictionary in each record into a tuple without a label.\n",
        "image_dataset = image_dataset.map(\n",
        "  lambda data_dict: (tf.transpose(list(data_dict.values())), )\n",
        ")\n",
        "\n",
        "# Turn each patch into a batch.\n",
        "image_dataset = image_dataset.batch(patch_width * patch_height)"
      ],
      "metadata": {
        "id": "KPHrWVYC4iLW"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate predictions for the image pixels\n",
        "\n",
        "To get predictions in each pixel, run the image dataset through the trained model using `model.predict()`.  Print the first prediction to see that the output is a list of the three class probabilities for each pixel.  Running all predictions might take a while."
      ],
      "metadata": {
        "id": "Xq5JuJo57xQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run prediction in batches, with as many steps as there are patches.\n",
        "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
        "\n",
        "# Note that the predictions come as a numpy array.  Check the first one.\n",
        "print(predictions[0])\n",
        "\n",
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUWvO_5m4iNu",
        "outputId": "dda7e2c2-2cd7-4bde-e9ea-0200765080b2"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12845056, 1, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write the predictions to a TFRecord file\n",
        "\n",
        "Now that there's a list of class probabilities in `predictions`, it's time to write them back into a file, optionally including a class label which is simply the index of the maximum probability.  We'll write directly from TensorFlow to a file in the output Cloud Storage bucket.\n",
        "\n",
        "Iterate over the list, compute class label and write the class and the probabilities in patches.  Specifically, we need to write the pixels into the file as patches in the same order they came out.  The records are written as serialized `tf.train.Example` protos.  This might take a while."
      ],
      "metadata": {
        "id": "Cb4Jtu7670NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Writing to file ' + OUTPUT_IMAGE_FILE)\n",
        "\n",
        "# Instantiate the writer.\n",
        "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
        "\n",
        "# Every patch-worth of predictions we'll dump an example into the output\n",
        "# file with a single feature that holds our predictions. Since our predictions\n",
        "# are already in the order of the exported data, the patches we create here\n",
        "# will also be in the right order.\n",
        "patch = [[], [], [], [], [], [], [], [], [], []]\n",
        "cur_patch = 1\n",
        "for prediction in predictions:\n",
        "  patch[0].append(tf.argmax(prediction, 1))\n",
        "  patch[1].append(prediction[0][0])\n",
        "  patch[2].append(prediction[0][1])\n",
        "  patch[3].append(prediction[0][2])\n",
        "  patch[4].append(prediction[0][3])\n",
        "  patch[5].append(prediction[0][4])\n",
        "  patch[6].append(prediction[0][5])\n",
        "  patch[7].append(prediction[0][6])\n",
        "  patch[8].append(prediction[0][7])\n",
        "  patch[9].append(prediction[0][8])\n",
        "  # Once we've seen a patches-worth of class_ids...\n",
        "  if (len(patch[0]) == patch_width * patch_height):\n",
        "    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
        "    # Create an example\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              int64_list=tf.train.Int64List(\n",
        "                  value=patch[0])),\n",
        "          'class1': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[1])),\n",
        "          'class2': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[2])),\n",
        "          'class3': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[3])),\n",
        "          'class4': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[4])),\n",
        "          'class5': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[5])),\n",
        "          'class6': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[6])),\n",
        "          'class7': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[7])),\n",
        "          'class8': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[8])),\n",
        "          'class9': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[9])),\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example to the file and clear our patch array so it's ready for\n",
        "    # another batch of class ids\n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = [[], [], [], [], [], [], [], [], [], []]\n",
        "    cur_patch += 1\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dvycm5f4iPz",
        "outputId": "3deb5bbc-2a6c-4d08-d3f5-300f86131c65"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing to file gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnndemo.TFRecord\n",
            "Done with patch 1 of 49...\n",
            "Done with patch 2 of 49...\n",
            "Done with patch 3 of 49...\n",
            "Done with patch 4 of 49...\n",
            "Done with patch 5 of 49...\n",
            "Done with patch 6 of 49...\n",
            "Done with patch 7 of 49...\n",
            "Done with patch 8 of 49...\n",
            "Done with patch 9 of 49...\n",
            "Done with patch 10 of 49...\n",
            "Done with patch 11 of 49...\n",
            "Done with patch 12 of 49...\n",
            "Done with patch 13 of 49...\n",
            "Done with patch 14 of 49...\n",
            "Done with patch 15 of 49...\n",
            "Done with patch 16 of 49...\n",
            "Done with patch 17 of 49...\n",
            "Done with patch 18 of 49...\n",
            "Done with patch 19 of 49...\n",
            "Done with patch 20 of 49...\n",
            "Done with patch 21 of 49...\n",
            "Done with patch 22 of 49...\n",
            "Done with patch 23 of 49...\n",
            "Done with patch 24 of 49...\n",
            "Done with patch 25 of 49...\n",
            "Done with patch 26 of 49...\n",
            "Done with patch 27 of 49...\n",
            "Done with patch 28 of 49...\n",
            "Done with patch 29 of 49...\n",
            "Done with patch 30 of 49...\n",
            "Done with patch 31 of 49...\n",
            "Done with patch 32 of 49...\n",
            "Done with patch 33 of 49...\n",
            "Done with patch 34 of 49...\n",
            "Done with patch 35 of 49...\n",
            "Done with patch 36 of 49...\n",
            "Done with patch 37 of 49...\n",
            "Done with patch 38 of 49...\n",
            "Done with patch 39 of 49...\n",
            "Done with patch 40 of 49...\n",
            "Done with patch 41 of 49...\n",
            "Done with patch 42 of 49...\n",
            "Done with patch 43 of 49...\n",
            "Done with patch 44 of 49...\n",
            "Done with patch 45 of 49...\n",
            "Done with patch 46 of 49...\n",
            "Done with patch 47 of 49...\n",
            "Done with patch 48 of 49...\n",
            "Done with patch 49 of 49...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the classifications to an Earth Engine asset\n",
        "\n",
        "## Verify the existence of the predictions file\n",
        "\n",
        "At this stage, there should be a predictions TFRecord file sitting in the output Cloud Storage bucket.  Use the `gsutil` command to verify that the predictions image (and associated mixer JSON) exist and have non-zero size.\n",
        "\n"
      ],
      "metadata": {
        "id": "wuB69p6uEZk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil ls -l {OUTPUT_IMAGE_FILE}\n",
        "\n",
        "print('Uploading to ' + OUTPUT_ASSET_ID)\n",
        "\n",
        "# Start the upload.\n",
        "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PdMGSiv4iUE",
        "outputId": "0ea53250-2df5-430a-fd36-35e7b14c640a"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 475280057  2022-06-06T17:31:55Z  gs://landcover_samples_nlcd2019_tfrecord_june2022/spurge_temporalcnndemo.TFRecord\n",
            "TOTAL: 1 objects, 475280057 bytes (453.26 MiB)\n",
            "Uploading to users/lakex055/spurge_temporalcnndemo\n",
            "Started upload task with ID: FKKMRPQ44JPMS3YXF5PQNPAO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map the Prediction!"
      ],
      "metadata": {
        "id": "pIOTWY7tE7Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "\n",
        "predictions_image = ee.Image(OUTPUT_ASSET_ID)\n",
        "\n",
        "prediction_vis = {\n",
        "  'bands': 'prediction',\n",
        "  'min': 0,\n",
        "  'max': 2,\n",
        "  'palette': ['red', 'green', 'blue']\n",
        "}\n",
        "probability_vis = {'bands': ['class8', 'class1', 'class6'], 'max': 0.5}\n",
        "\n",
        "prediction_map_id = predictions_image.getMapId(prediction_vis)\n",
        "probability_map_id = predictions_image.getMapId(probability_vis)\n",
        "\n",
        "map = folium.Map(location=[37.6413, -122.2582])\n",
        "folium.TileLayer(\n",
        "  tiles=prediction_map_id['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='prediction',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probability_map_id['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "id": "lfheefew4iWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h-X2mKjI4iYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IDGLN4CP4iac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QGRT2Izt4icz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0xeshFcG4igB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Agm8lucB4jmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WocFofw24jo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y8bNY_bc4jrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rk_MeVUo4jtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XQ0qIZMm4jvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fgRqlVID4jxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Gather Landsat ImageCollection Mosaic from Date/Points Input\n"
      ],
      "metadata": {
        "id": "V4Ou7n3ewbDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Function to Gather Landsat ImageCollection Mosaic from Date/Points Input\n",
        "\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameImageBands(img, year, season):\n",
        "  return img.select(\n",
        "      ['Blue_median', 'Green_median', 'Red_median', 'NIR_median', \n",
        "       'SWIR1_median', 'SWIR2_median', 'QA_PIXEL_median', 'QA_RADSAT_median', 'NDVI_median'],\n",
        "      ['Blue'+str(season)+str(year), 'Green'+str(season)+str(year), 'Red'+str(season)+str(year), 'NIR'+str(season)+str(year),\n",
        "       'SWIR1'+str(season)+str(year), 'SWIR2'+str(season)+str(year), 'QA_PIXEL'+str(season)+str(year), 'QA_RADSAT'+str(season)+str(year), 'NDVI'+str(season)+str(year)])\n",
        "\n",
        "\n",
        "def getLandsatMosaicFromPoints(year, points):\n",
        "  '''\n",
        "  #Time-series extraction developed from\n",
        "  #https://developers.google.com/earth-engine/tutorials/community/time-series-visualization-with-altair#combine_dataframes  \n",
        "\n",
        "  '''\n",
        "\n",
        "  #if Year is between 1985 and 1999 use Landsat 5 TM imagery\n",
        "  if 1985 <= year <= 1999:\n",
        "\n",
        "    tmColMarchApril = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMarchApril = renameImageBands(tmColMarchApril, year, 'MarchApril')\n",
        "\n",
        "    tmColMayJune = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMayJune = renameImageBands(tmColMayJune, year, 'MayJune')\n",
        "\n",
        "    tmColJulyAug = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColJulyAug = renameImageBands(tmColJulyAug, year, 'JulyAug')\n",
        "\n",
        "    landsat5ImageCol = [tmColMarchApril, tmColMayJune, tmColJulyAug]\n",
        "    return landsat5ImageCol\n",
        "\n",
        "  #if Year is between 2000 and 2012 use mosaic from Landsat 5 TM and Landsat 7 ETM imagery\n",
        "  if 2000 <= year <= 2012:\n",
        "\n",
        "    etmColMarchApril = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMarchApril = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MarchApril = ee.ImageCollection([etmColMarchApril, tmColMarchApril])\n",
        "\n",
        "    etmColMarchApril = MarchApril.reduce('median')\n",
        "\n",
        "    etmColMayJune = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColMayJune = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MayJune = ee.ImageCollection([etmColMayJune, tmColMayJune])\n",
        "\n",
        "    etmColMayJune = MayJune.reduce('median')\n",
        "\n",
        "    etmColJulyAug = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    tmColJulyAug = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    JulyAug = ee.ImageCollection([etmColJulyAug, tmColJulyAug])\n",
        "\n",
        "    etmColJulyAug = JulyAug.reduce('median')\n",
        "\n",
        "    landsat5_7ImageCol = ee.ImageCollection([etmColMarchApril, etmColMayJune, etmColJulyAug])\n",
        "    return landsat5_7ImageCol\n",
        "\n",
        "  #if Year is between 2013 and 2020 use mosaic from Landsat 7 ETM and Landsat 8 OLI imagery\n",
        "  if 2013 <= year <= 2020:\n",
        "\n",
        "    etmColMarchApril = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    oliColMarchApril = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "      .filterDate('{}-03-01'.format(year), '{}-04-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepOli) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MarchApril = ee.ImageCollection([etmColMarchApril, oliColMarchApril])\n",
        "\n",
        "    etmColMarchApril = MarchApril.reduce('median')\n",
        "\n",
        "    etmColMayJune = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    oliColMayJune = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "      .filterDate('{}-05-01'.format(year), '{}-06-30'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepOli) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    MayJune = ee.ImageCollection([etmColMayJune, oliColMayJune])\n",
        "\n",
        "    etmColMayJune = MayJune.reduce('median')\n",
        "\n",
        "    etmColJulyAug = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepEtm) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median') \\\n",
        "\n",
        "    oliColJulyAug = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "      .filterDate('{}-07-01'.format(year), '{}-08-31'.format(year)) \\\n",
        "      .filterBounds(points) \\\n",
        "      .map(maskQuality) \\\n",
        "      .map(prepOli) \\\n",
        "      .map(addNDVI) \\\n",
        "      .reduce('median')\n",
        "\n",
        "    JulyAug = ee.ImageCollection([etmColJulyAug, oliColJulyAug])\n",
        "\n",
        "    etmColJulyAug = JulyAug.reduce('median')\n",
        "\n",
        "    landsat7_8ImageCol = ee.ImageCollection([etmColMarchApril, etmColMayJune, etmColJulyAug])\n",
        "    return landsat7_8ImageCol\n",
        "\n",
        "\n",
        "year = 1987\n",
        "\n",
        "landsatCol = getLandsatMosaicFromPoints(year, newpts)\n",
        "\n",
        "image1 = landsatCol[0]\n",
        "image2 = landsatCol[1]\n",
        "image3 = landsatCol[2]\n",
        "\n",
        "image1_fc = image1.sampleRegions(collection=newpts, properties=['class'], scale=30)\n",
        "image2_fc = image2.sampleRegions(collection=newpts, properties=['class'], scale=30)\n",
        "image3_fc = image3.sampleRegions(collection=newpts, properties=['class'], scale=30)\n",
        "\n",
        "\n",
        "# Define a function to transfer feature properties to a dictionary.\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)\n",
        "\n",
        "image1_db_dict = fc_to_dict(image1_fc).getInfo()\n",
        "image2_db_dict = fc_to_dict(image2_fc).getInfo()\n",
        "image3_db_dict = fc_to_dict(image3_fc).getInfo()\n",
        "\n",
        "image1_df = pd.DataFrame(image1_db_dict)\n",
        "image2_df = pd.DataFrame(image2_db_dict)\n",
        "image3_df = pd.DataFrame(image3_db_dict)\n",
        "\n",
        "display(image1_df)\n",
        "\n",
        "data_frames = [image1_df, image2_df, image3_df]\n",
        "\n",
        "\n",
        "from functools import reduce\n",
        "df_merged = reduce(lambda left,right: pd.merge(left, right, on='system:index', how='outer'), data_frames).fillna(np.nan)\n",
        "display(df_merged)\n",
        "\n",
        "df_merged_dropna = df_merged.dropna(axis=0, how = 'any')\n",
        "#display(df_merged_dropna)\n",
        "\n",
        "\n",
        "df_merged_removeQA = df_merged_dropna.drop(['QA_PIXEL_mean_1', 'QA_RADSAT_mean_1', 'QA_PIXEL_mean_2', 'QA_RADSAT_mean_2', 'QA_PIXEL_mean_3', 'QA_RADSAT_mean_3',\n",
        "                                     'QA_PIXEL_mean_4', 'QA_RADSAT_mean_4', 'QA_PIXEL_mean_5', 'QA_RADSAT_mean_5', 'QA_PIXEL_mean_6', 'QA_RADSAT_mean_6',\n",
        "                                     'QA_PIXEL_mean_7', 'QA_RADSAT_mean_7', 'QA_PIXEL_mean_8', 'QA_RADSAT_mean_8', 'QA_PIXEL_mean_9', 'QA_RADSAT_mean_9',\n",
        "                                     'class_x', 'class_y', '.geo_x', '.geo_y', '.geo', 'system:index'], 1)\n",
        "display(df_merged_removeQA)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data_frames = [db_MarchApril2018_df, db_MayJune2018_df, db_JulyAug2018_df,\n",
        "               db_MarchApril2019_df, db_MayJune2019_df, db_JulyAug2019_df,\n",
        "               db_MarchApril2020_df, db_MayJune2020_df, db_JulyAug2020_df]\n",
        "\n",
        "from functools import reduce\n",
        "df_merged = reduce(lambda left,right: pd.merge(left, right, on='system:index', how='outer'), data_frames).fillna(np.nan)\n",
        "#display(df_merged)\n",
        "\n",
        "df_merged_dropna = df_merged.dropna(axis=0, how = 'any')\n",
        "#display(df_merged_dropna)\n",
        "\n",
        "\n",
        "df_merged_removeQA = df_merged_dropna.drop(['QA_PIXEL_mean_1', 'QA_RADSAT_mean_1', 'QA_PIXEL_mean_2', 'QA_RADSAT_mean_2', 'QA_PIXEL_mean_3', 'QA_RADSAT_mean_3',\n",
        "                                     'QA_PIXEL_mean_4', 'QA_RADSAT_mean_4', 'QA_PIXEL_mean_5', 'QA_RADSAT_mean_5', 'QA_PIXEL_mean_6', 'QA_RADSAT_mean_6',\n",
        "                                     'QA_PIXEL_mean_7', 'QA_RADSAT_mean_7', 'QA_PIXEL_mean_8', 'QA_RADSAT_mean_8', 'QA_PIXEL_mean_9', 'QA_RADSAT_mean_9',\n",
        "                                     'class_x', 'class_y', '.geo_x', '.geo_y', '.geo', 'system:index'], 1)\n",
        "display(df_merged_removeQA)\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to transfer feature properties to a dictionary.\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)\n",
        "\n",
        "train_db_dict = fc_to_dict(subset_train_db).getInfo()\n",
        "train_df = pd.DataFrame(train_db_dict)\n",
        "display(train_df)\n",
        "#print(nbr_df.dtypes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KQLfbROywaIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Landsat-8 Imagery from 2018, 2019, and 2020 (Centered on 2019 - corresponding to NLCD 2019 land cover classes in the training points)"
      ],
      "metadata": {
        "id": "U51ZVmh7gg6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##########\n",
        "## 2018 ##\n",
        "##########\n",
        "\n",
        "etmColMarchApril2018 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2018-03-01', '2018-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "oliColMarchApril2018 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2018-03-01', '2018-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "MarchApril2018 = ee.ImageCollection([etmColMarchApril2018, oliColMarchApril2018])\n",
        "\n",
        "etmColMarchApril2018 = MarchApril2018.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_1(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_1', 'Green_mean_1', 'Red_mean_1', 'NIR_mean_1','SWIR1_mean_1', 'SWIR2_mean_1', 'QA_PIXEL_mean_1', 'QA_RADSAT_mean_1', 'NDVI_mean_1'])\n",
        "\n",
        "etmColMarchApril2018 = renameEtm_mean_1(etmColMarchApril2018)\n",
        "\n",
        "etmColMayJune2018 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2018-05-01', '2018-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "oliColMayJune2018 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2018-05-01', '2018-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "MayJune2018 = ee.ImageCollection([etmColMayJune2018, oliColMayJune2018])\n",
        "\n",
        "etmColMayJune2018 = MayJune2018.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_2(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_2', 'Green_mean_2', 'Red_mean_2', 'NIR_mean_2','SWIR1_mean_2', 'SWIR2_mean_2', 'QA_PIXEL_mean_2', 'QA_RADSAT_mean_2', 'NDVI_mean_2'])\n",
        "\n",
        "etmColMayJune2018 = renameEtm_mean_2(etmColMayJune2018)\n",
        "\n",
        "etmColJulyAug2018 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2018-07-01', '2018-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean') \\\n",
        "\n",
        "oliColJulyAug2018 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2018-07-01', '2018-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "JulyAug2018 = ee.ImageCollection([etmColJulyAug2018, oliColJulyAug2018])\n",
        "\n",
        "etmColJulyAug2018 = JulyAug2018.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_3(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_3', 'Green_mean_3', 'Red_mean_3', 'NIR_mean_3','SWIR1_mean_3', 'SWIR2_mean_3', 'QA_PIXEL_mean_3', 'QA_RADSAT_mean_3', 'NDVI_mean_3'])\n",
        "\n",
        "etmColJulyAug2018 = renameEtm_mean_3(etmColJulyAug2018)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########\n",
        "## 2019 ##\n",
        "##########\n",
        "\n",
        "etmColMarchApril2019 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2019-03-01', '2019-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "oliColMarchApril2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2019-03-01', '2019-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "MarchApril2019 = ee.ImageCollection([etmColMarchApril2019, oliColMarchApril2019])\n",
        "\n",
        "etmColMarchApril2019 = MarchApril2019.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_4(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_4', 'Green_mean_4', 'Red_mean_4', 'NIR_mean_4','SWIR1_mean_4', 'SWIR2_mean_4', 'QA_PIXEL_mean_4', 'QA_RADSAT_mean_4', 'NDVI_mean_4'])\n",
        "\n",
        "etmColMarchApril2019 = renameEtm_mean_4(etmColMarchApril2019)\n",
        "\n",
        "etmColMayJune2019 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2019-05-01', '2019-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "oliColMayJune2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2019-05-01', '2019-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "MayJune2019 = ee.ImageCollection([etmColMayJune2019, oliColMayJune2019])\n",
        "\n",
        "etmColMayJune2019 = MayJune2019.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_5(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_5', 'Green_mean_5', 'Red_mean_5', 'NIR_mean_5','SWIR1_mean_5', 'SWIR2_mean_5', 'QA_PIXEL_mean_5', 'QA_RADSAT_mean_5', 'NDVI_mean_5'])\n",
        "\n",
        "etmColMayJune2019 = renameEtm_mean_5(etmColMayJune2019)\n",
        "\n",
        "etmColJulyAug2019 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2019-07-01', '2019-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean') \\\n",
        "\n",
        "oliColJulyAug2019 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2019-07-01', '2019-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "JulyAug2019 = ee.ImageCollection([etmColJulyAug2019, oliColJulyAug2019])\n",
        "\n",
        "etmColJulyAug2019 = JulyAug2019.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_6(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_6', 'Green_mean_6', 'Red_mean_6', 'NIR_mean_6','SWIR1_mean_6', 'SWIR2_mean_6', 'QA_PIXEL_mean_6', 'QA_RADSAT_mean_6', 'NDVI_mean_6'])\n",
        "\n",
        "etmColJulyAug2019 = renameEtm_mean_6(etmColJulyAug2019)\n",
        "\n",
        "\n",
        "##########\n",
        "## 2020 ##\n",
        "##########\n",
        "\n",
        "etmColMarchApril2020 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2020-03-01', '2020-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "oliColMarchApril2020 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2020-03-01', '2020-04-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "MarchApril2020 = ee.ImageCollection([etmColMarchApril2020, oliColMarchApril2020])\n",
        "\n",
        "etmColMarchApril2020 = MarchApril2020.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_7(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_7', 'Green_mean_7', 'Red_mean_7', 'NIR_mean_7','SWIR1_mean_7', 'SWIR2_mean_7', 'QA_PIXEL_mean_7', 'QA_RADSAT_mean_7', 'NDVI_mean_7'])\n",
        "\n",
        "etmColMarchApril2020 = renameEtm_mean_7(etmColMarchApril2020)\n",
        "\n",
        "etmColMayJune2020 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2020-05-01', '2020-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "oliColMayJune2020 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2020-05-01', '2020-06-30') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "MayJune2020 = ee.ImageCollection([etmColMayJune2020, oliColMayJune2020])\n",
        "\n",
        "etmColMayJune2020 = MayJune2020.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_8(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_8', 'Green_mean_8', 'Red_mean_8', 'NIR_mean_8','SWIR1_mean_8', 'SWIR2_mean_8', 'QA_PIXEL_mean_8', 'QA_RADSAT_mean_8', 'NDVI_mean_8'])\n",
        "\n",
        "etmColMayJune2020 = renameEtm_mean_8(etmColMayJune2020)\n",
        "\n",
        "etmColJulyAug2020 = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2') \\\n",
        "  .filterDate('2020-07-01', '2020-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepEtm) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean') \\\n",
        "\n",
        "oliColJulyAug2020 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
        "  .filterDate('2020-07-01', '2020-08-31') \\\n",
        "  .filterBounds(pts) \\\n",
        "  .map(maskQuality) \\\n",
        "  .map(prepOli) \\\n",
        "  .map(addNDVI) \\\n",
        "  .reduce('mean')\n",
        "\n",
        "JulyAug2020 = ee.ImageCollection([etmColJulyAug2020, oliColJulyAug2020])\n",
        "\n",
        "etmColJulyAug2020 = JulyAug2020.reduce('mean')\n",
        "\n",
        "# Selects and renames bands of interest for TM/ETM+.\n",
        "def renameEtm_mean_9(img):\n",
        "  return img.select(\n",
        "      ['Blue_mean_mean', 'Green_mean_mean', 'Red_mean_mean', 'NIR_mean_mean', 'SWIR1_mean_mean', 'SWIR2_mean_mean', 'QA_PIXEL_mean_mean', 'QA_RADSAT_mean_mean', 'NDVI_mean_mean'],\n",
        "      ['Blue_mean_9', 'Green_mean_9', 'Red_mean_9', 'NIR_mean_9','SWIR1_mean_9', 'SWIR2_mean_9', 'QA_PIXEL_mean_9', 'QA_RADSAT_mean_9', 'NDVI_mean_9'])\n",
        "\n",
        "etmColJulyAug2020 = renameEtm_mean_9(etmColJulyAug2020)\n",
        "\n",
        "etmColJulyAug2020.getInfo()\n"
      ],
      "metadata": {
        "id": "9oqLZm-Helq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract Landsat-8 Bands from Points, Format into Pandas DataFrame"
      ],
      "metadata": {
        "id": "U_HkdxmEhkeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sample Regions\n",
        "\n",
        "# 2018\n",
        "etmColMarchApril2018_fc = etmColMarchApril2018.sampleRegions(collection=pts, properties=['class'], scale=30)\n",
        "#print(etmColMarchApril2018_fc.getInfo())\n",
        "etmColMayJune2018_fc = etmColMayJune2018.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColMayJune2018_fc.getInfo())\n",
        "etmColJulyAug2018_fc = etmColJulyAug2018.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColJulyAug2018_fc.getInfo())\n",
        "\n",
        "# 2019\n",
        "etmColMarchApril2019_fc = etmColMarchApril2019.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColMarchApril2019_fc.getInfo())\n",
        "etmColMayJune2019_fc = etmColMayJune2019.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColMayJune2019_fc.getInfo())\n",
        "etmColJulyAug2019_fc = etmColJulyAug2019.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColJulyAug2019_fc.getInfo())\n",
        "\n",
        "# 2020\n",
        "etmColMarchApril2020_fc = etmColMarchApril2020.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColMarchApril2020_fc.getInfo())\n",
        "etmColMayJune2020_fc = etmColMayJune2020.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColMayJune2020_fc.getInfo())\n",
        "etmColJulyAug2020_fc = etmColJulyAug2020.sampleRegions(collection=pts, properties=['class'], scale=30, geometries=True)\n",
        "#print(etmColJulyAug2020_fc.getInfo())\n",
        "\n",
        "\n",
        "\n",
        "# Export feature class assets\n",
        "outputBucket = 'landcover_samples_nlcd2019_onemillionpoints'\n",
        "# Make sure the bucket exists.\n",
        "print('Found Cloud Storage bucket.' if tf.io.gfile.exists('gs://' + outputBucket) \n",
        "    else 'Output Cloud Storage bucket does not exist.')\n",
        "\n",
        "\n",
        "# 2018\n",
        "task1 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColMarchApril2018_fc,\n",
        "    description='etmColMarchApril2018_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColMarchApril2018_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "task2 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColMayJune2018_fc,\n",
        "    description='etmColMayJune2018_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColMayJune2018_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "task3 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColJulyAug2018_fc,\n",
        "    description='etmColJulyAug2018_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColJulyAug2018_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "# 2019\n",
        "task4 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColMarchApril2019_fc,\n",
        "    description='etmColMarchApril2019_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColMarchApril2019_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "task5 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColMayJune2019_fc,\n",
        "    description='etmColMayJune2019_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColMayJune2019_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "task6 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColJulyAug2019_fc,\n",
        "    description='etmColJulyAug2019_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColJulyAug2019_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "# 2020\n",
        "task7 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColMarchApril2020_fc,\n",
        "    description='etmColMarchApril2020_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColMarchApril2020_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "task8 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColMayJune2020_fc,\n",
        "    description='etmColMayJune2020_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColMayJune2020_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "task9 = ee.batch.Export.table.toCloudStorage(\n",
        "    collection=etmColJulyAug2020_fc,\n",
        "    description='etmColJulyAug2020_fc_landcover export',\n",
        "    bucket = outputBucket,\n",
        "    fileNamePrefix='etmColJulyAug2020_fc_landcover',\n",
        "    fileFormat='CSV')\n",
        "\n",
        "#Export/Start Tasks\n",
        "\n",
        "task1.start()\n",
        "task2.start()\n",
        "task3.start()\n",
        "task4.start()\n",
        "task5.start()\n",
        "task6.start()\n",
        "task7.start()\n",
        "task8.start()\n",
        "task9.start()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0d4WryBWelsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Re-Import Feature Class Assets (no longer hosted on EE and thus not restricted to size limits) and format to pandas DataFrame\n",
        "# Depends on import gcsfs\n",
        "\n",
        "#2018\n",
        "db_MarchApril2018_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColMarchApril2018_fc_landcover.csv')\n",
        "#display(db_MarchApril2018_df)\n",
        "db_MayJune2018_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColMayJune2018_fc_landcover.csv')\n",
        "#display(db_MayJune2018_df)\n",
        "db_JulyAug2018_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColJulyAug2018_fc_landcover.csv')\n",
        "#display(db_JulyAug2018_df)\n",
        "\n",
        "\n",
        "#2019\n",
        "db_MarchApril2019_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColMarchApril2019_fc_landcover.csv')\n",
        "#display(db_MarchApril2019_df)\n",
        "db_MayJune2019_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColMayJune2019_fc_landcover.csv')\n",
        "#display(db_MayJune2019_df)\n",
        "db_JulyAug2019_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColJulyAug2019_fc_landcover.csv')\n",
        "#display(db_JulyAug2019_df)\n",
        "\n",
        "\n",
        "#2020\n",
        "db_MarchApril2020_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColMarchApril2020_fc_landcover.csv')\n",
        "#display(db_MarchApril2020_df)\n",
        "db_MayJune2020_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColMayJune2020_fc_landcover.csv')\n",
        "#display(db_MayJune2020_df)\n",
        "db_JulyAug2020_df = pd.read_csv('gs://landcover_samples_nlcd2019_onemillionpoints/etmColJulyAug2020_fc_landcover.csv')\n",
        "#display(db_JulyAug2020_df)"
      ],
      "metadata": {
        "id": "Fj5ZW3WY3O7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge Landsat-8 <> LandCover Points into one DataFrame"
      ],
      "metadata": {
        "id": "_o8Jy7tliW8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_frames = [db_MarchApril2018_df, db_MayJune2018_df, db_JulyAug2018_df,\n",
        "               db_MarchApril2019_df, db_MayJune2019_df, db_JulyAug2019_df,\n",
        "               db_MarchApril2020_df, db_MayJune2020_df, db_JulyAug2020_df]\n",
        "\n",
        "from functools import reduce\n",
        "df_merged = reduce(lambda left,right: pd.merge(left, right, on='system:index', how='outer'), data_frames).fillna(np.nan)\n",
        "#display(df_merged)\n",
        "\n",
        "df_merged_dropna = df_merged.dropna(axis=0, how = 'any')\n",
        "#display(df_merged_dropna)\n",
        "\n",
        "\n",
        "df_merged_removeQA = df_merged_dropna.drop(['QA_PIXEL_mean_1', 'QA_RADSAT_mean_1', 'QA_PIXEL_mean_2', 'QA_RADSAT_mean_2', 'QA_PIXEL_mean_3', 'QA_RADSAT_mean_3',\n",
        "                                     'QA_PIXEL_mean_4', 'QA_RADSAT_mean_4', 'QA_PIXEL_mean_5', 'QA_RADSAT_mean_5', 'QA_PIXEL_mean_6', 'QA_RADSAT_mean_6',\n",
        "                                     'QA_PIXEL_mean_7', 'QA_RADSAT_mean_7', 'QA_PIXEL_mean_8', 'QA_RADSAT_mean_8', 'QA_PIXEL_mean_9', 'QA_RADSAT_mean_9',\n",
        "                                     'class_x', 'class_y', '.geo_x', '.geo_y', '.geo', 'system:index'], 1)\n",
        "display(df_merged_removeQA)\n",
        "\n"
      ],
      "metadata": {
        "id": "ARb8v3H2elvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export DataFrame to CSV"
      ],
      "metadata": {
        "id": "3db0Ks7NjLtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged_removeQA.to_csv(\"example2_1dcnn_april2022.csv\")"
      ],
      "metadata": {
        "id": "HVYg2R-YelxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Functions to read and compute spectral features on SITS \n"
      ],
      "metadata": {
        "id": "7g9aRjCnjzUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" \n",
        "\tSome functions to read and compute spectral features on SITS\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "import csv\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "#---------------------- SATELLITE MODULE\n",
        "#-----------------------------------------------------------------------\n",
        "#final_class_label = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12']\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def readSITSData(name_file):\n",
        "\t\"\"\"\n",
        "\t\tRead the data contained in name_file\n",
        "\t\tINPUT:\n",
        "\t\t\t- name_file: file where to read the data\n",
        "\t\tOUTPUT:\n",
        "\t\t\t- X: variable vectors for each example\n",
        "\t\t\t- polygon_ids: id polygon (use e.g. for validation set)\n",
        "\t\t\t- Y: label for each example\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tdata = pd.read_table(name_file, sep=',', header=None)\n",
        "\t\n",
        "\ty_data = data.iloc[:,0]\n",
        "\ty = np.asarray(y_data.values, dtype='uint8')\n",
        "\t\n",
        "\tpolygonID_data = data.iloc[:,1]\n",
        "\tpolygon_ids = polygonID_data.values\n",
        "\tpolygon_ids = np.asarray(polygon_ids, dtype='uint16')\n",
        "\t\t\n",
        "\tX_data = data.iloc[:,2:]\n",
        "\tX = X_data.values\n",
        "\tX = np.asarray(X, dtype='float32')\n",
        "\n",
        "\treturn  X, polygon_ids, y\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def addFeatures(X):\n",
        "\t\"\"\"\n",
        "\t\tRead the data contained in name_file\n",
        "\t\tINPUT:\n",
        "\t\t\t- X: orginal X features composed of threes bands (NIR-R-G)\n",
        "\t\t\t\tin the following order \n",
        "\t\t\t\t\t[date1.NIR, date1.R, date1.G, ..., dateD.NIR, dateD.R, dateD.G]\n",
        "\t\tOUTPUT:\n",
        "\t\t\t- X_features: orginal_X with the addition of NDVI, NDWI and Brilliance\n",
        "\t\t\t\tin the following order\t\n",
        "\t\t\t\t\t[X, date1.NDVI, ..., dateD.NDVI, date1.NDWI, ..., dateD.NDWI, date1.Brilliance, ..., dateD.Brilliance]\n",
        "\t\"\"\"\n",
        "\tn_channels = 3\n",
        "\t\n",
        "\tNIR = X[:,0::n_channels]\n",
        "\tNIR = np.array(NIR)\n",
        "\tNIR = NIR.astype(np.float)\n",
        "\tR = X[:,1::n_channels]\n",
        "\tR = np.array(R)\n",
        "\tR = R.astype(np.float)\n",
        "\tG = X[:,2::n_channels]\n",
        "\tG = np.array(G)\n",
        "\tG = G.astype(np.float)\t\n",
        "\t\n",
        "\tNDVI = np.where(NIR+R!=0., (NIR-R)/(NIR+R), 0.)\n",
        "\tNDVI = NDVI.astype(float)\n",
        "\t\n",
        "\t\n",
        "\tNDWI = np.where(G+NIR!=0., (G-NIR)/(G+NIR), 0.)\n",
        "\tNDWI = NDWI.astype(float)\n",
        "\t\n",
        "\tBrilliance = np.sqrt((NIR*NIR + R*R + G*G)/3.0)\n",
        "\tBrilliance = Brilliance.astype(float)\n",
        "\t\n",
        "\treturn NDVI, NDWI, Brilliance\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def computeNDVI(X, n_channels):\n",
        "\t\"\"\"\n",
        "\t\tRead the data contained in name_file\n",
        "\t\tINPUT:\n",
        "\t\t\t- X: orginal X features composed of threes bands (NIR-R-G)\n",
        "\t\t\t\tin the following order \n",
        "\t\t\t\t\t[date1.NIR, date1.R, date1.G, ..., dateD.NIR, dateD.R, dateD.G]\n",
        "\t\tOUTPUT:\n",
        "\t\t\t- X_features: orginal_X with the addition of NDVI, NDWI and Brilliance\n",
        "\t\t\t\tin the following order\t\n",
        "\t\t\t\t\t[X, date1.NDVI, ..., dateD.NDVI, date1.NDWI, ..., dateD.NDWI, date1.Brilliance, ..., dateD.Brilliance]\n",
        "\t\"\"\"\n",
        "\t\n",
        "\tNIR = X[:,0::n_channels]\n",
        "\tNIR = np.array(NIR)\n",
        "\tNIR = NIR.astype(np.float)\n",
        "\tR = X[:,1::n_channels]\n",
        "\tR = np.array(R)\n",
        "\tR = R.astype(np.float)\n",
        "\t\n",
        "\tNDVI = np.where(NIR+R!=0., (NIR-R)/(NIR+R), 0.)\n",
        "\treturn NDVI\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def addingfeat_reshape_data(X, feature_strategy, nchannels):\n",
        "\t\"\"\"\n",
        "\t\tReshaping (feature format (3 bands): d1.b1 d1.b2 d1.b3 d2.b1 d2.b2 d2.b3 ...)\n",
        "\t\tINPUT:\n",
        "\t\t\t-X: original feature vector ()\n",
        "\t\t\t-feature_strategy: used features (options: SB, NDVI, SB3feat)\n",
        "\t\t\t-nchannels: number of channels\n",
        "\t\tOUTPUT:\n",
        "\t\t\t-new_X: data in the good format for Keras models\n",
        "\t\"\"\"\n",
        "\t\t\t\n",
        "\tif feature_strategy=='SB':\n",
        "\t\tprint(\"SPECTRAL BANDS-----------------------------------------\")\n",
        "\t\treturn X.reshape(X.shape[0],int(X.shape[1]/nchannels),nchannels)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\telif feature_strategy=='NDVI':\n",
        "\t\tprint(\"NDVI only----------------------------------------------\")\n",
        "\t\tnew_X = computeNDVI(X, nchannels)\n",
        "\t\treturn np.expand_dims(new_X, axis=2)\n",
        "\t\t\t\t\t\t\t\n",
        "\telif feature_strategy=='SB3feat':\n",
        "\t\tprint(\"SB + NDVI + NDWI + IB----------------------------------\")\n",
        "\t\tNDVI, NDWI, IB = addFeatures(X)\t\t\n",
        "\t\tnew_X = X.reshape(X.shape[0],int(X.shape[1]/nchannels),nchannels)\t\t\n",
        "\t\tnew_X = np.dstack((new_X, NDVI))\n",
        "\t\tnew_X = np.dstack((new_X, NDWI))\n",
        "\t\tnew_X = np.dstack((new_X, IB))\n",
        "\t\treturn new_X\n",
        "\telse:\n",
        "\t\tprint(\"Not referenced!!!-------------------------------------------\")\n",
        "\t\treturn -1\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def computingMinMax(X, per=2):\n",
        "\tmin_per = np.percentile(X, per, axis=(0,1))\n",
        "\tmax_per = np.percentile(X, 100-per, axis=(0,1))\n",
        "\treturn min_per, max_per\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def read_minMaxVal(minmax_file):\t\n",
        "\twith open(minmax_file, 'r') as f:\n",
        "\t\treader = csv.reader(f, delimiter=',')\n",
        "\t\tmin_per = next(reader)\n",
        "\t\tmax_per = next(reader)\n",
        "\tmin_per = [float(k) for k in min_per]\n",
        "\tmin_per = np.array(min_per)\n",
        "\tmax_per = [float(k) for k in max_per]\n",
        "\tmax_per = np.array(max_per)\n",
        "\treturn min_per, max_per\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def save_minMaxVal(minmax_file, min_per, max_per):\t\n",
        "\twith open(minmax_file, 'w') as f:\n",
        "\t\twriter = csv.writer(f, delimiter=',')\n",
        "\t\twriter.writerow(min_per)\n",
        "\t\twriter.writerow(max_per)\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def normalizingData(X, min_per, max_per):\n",
        "\treturn (X-min_per)/(max_per-min_per)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\n",
        "def extractValSet(X_train, polygon_ids_train, y_train, val_rate=0.1):\n",
        "\tunique_pol_ids_train, indices = np.unique(polygon_ids_train, return_inverse=True) #-- pold_ids_train = unique_pol_ids_train[indices]\n",
        "\tnb_pols = len(unique_pol_ids_train)\n",
        "\t\n",
        "\tind_shuffle = list(range(nb_pols))\n",
        "\trandom.shuffle(ind_shuffle)\n",
        "\tlist_indices = [[] for i in range(nb_pols)]\n",
        "\tshuffle_indices = [[] for i in range(nb_pols)]\n",
        "\t[ list_indices[ind_shuffle[val]].append(idx) for idx, val in enumerate(indices)]\t\t\t\t\t\n",
        "\t\t\n",
        "\tfinal_ind = list(itertools.chain.from_iterable(list_indices))\n",
        "\tm = len(final_ind)\n",
        "\tfinal_train = int(math.ceil(m*(1.0-val_rate)))\n",
        "\t\n",
        "\tshuffle_polygon_ids_train = polygon_ids_train[final_ind]\n",
        "\tid_final_train = shuffle_polygon_ids_train[final_train]\n",
        "\t\n",
        "\twhile shuffle_polygon_ids_train[final_train-1]==id_final_train:\n",
        "\t\tfinal_train = final_train-1\n",
        "\t\n",
        "\t\n",
        "\tnew_X_train = X_train[final_ind[:final_train],:,:]\n",
        "\tnew_y_train = y_train[final_ind[:final_train]]\n",
        "\tnew_X_val = X_train[final_ind[final_train:],:,:]\n",
        "\tnew_y_val = y_train[final_ind[final_train:]]\n",
        "\t\n",
        "\treturn new_X_train, new_y_train, new_X_val, new_y_val\n",
        "\t"
      ],
      "metadata": {
        "id": "PMlD11bnelzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "open(\"/content/drive/My Drive/Invasives Research UMN/Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example/train_dataset.csv\").read()\n",
        "\n",
        "res_path = '/content/drive/My Drive/Invasives Research UMN/Remote Sensing Master/Leafy Spurge Demography'\n",
        "sits_path = '/content/drive/My Drive/Invasives Research UMN/Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/example'\n",
        "feature = \"SB\"\n",
        "noarchi = 2\n",
        "norun = 0\n",
        "\n",
        "\n",
        "#-- Creating output path if does not exist\n",
        "if not os.path.exists(res_path):\n",
        "  print(\"ResPath DNE\")\n",
        "  os.makedirs(res_path)\n",
        "\t\n",
        "\t#---- Parameters to set\n",
        "n_channels = 7 #-- B G NDVI NIR Red SWIR1 SWIR2\n",
        "val_rate = 0.00\n",
        "\n",
        "\t#---- Evaluated metrics\n",
        "eval_label = ['OA', 'train_loss', 'train_time', 'test_time']\t\n",
        "\t\n",
        "\t#---- String variables\n",
        "train_str = 'train_dataset'\n",
        "test_str = 'test_dataset'\t\t\t\t\t\n",
        "\t#---- Get filenames\n",
        "train_file = sits_path + '/' + train_str + '.csv'\n",
        "test_file = sits_path + '/' + test_str + '.csv'\n",
        "print(\"train_file: \", train_file)\n",
        "print(\"test_file: \", test_file)\n",
        "\t\n",
        "\t#---- output files\t\t\t\n",
        "res_path = res_path + '/Archi' + str(noarchi) + '/'\n",
        "if not os.path.exists(res_path):\n",
        "  os.makedirs(res_path)\n",
        "  print(\"noarchi: \", noarchi)\n",
        "\t\n",
        "str_result = feature + '-' + train_str + '-noarchi' + str(noarchi) + '-norun' + str(norun) \n",
        "res_file = res_path + '/resultOA-' + str_result + '.csv'\n",
        "res_mat = np.zeros((len(eval_label),1))\n",
        "traintest_loss_file = res_path + '/trainingHistory-' + str_result + '.csv'\n",
        "conf_file = res_path + '/confMatrix-' + str_result + '.csv'\n",
        "out_model_file = res_path + '/bestmodel-' + str_result + '.h5'\n",
        "\n",
        "\n",
        "\t#---- Downloading\n",
        "X_train, polygon_ids_train, y_train = readSITSData(train_file)\n",
        "\n",
        "print(X_train.shape) #13336, 63\n",
        "X_test,  polygon_ids_test, y_test = readSITSData(test_file)\n",
        "print(X_train)\n",
        "print(polygon_ids_train)\n",
        "print(y_train.shape) #13336\n",
        "\n",
        "n_classes_test = len(np.unique(y_test))\n",
        "print(n_classes_test)\n",
        "n_classes_train = len(np.unique(y_train))\n",
        "print(n_classes_train)\n",
        "if(n_classes_test != n_classes_train):\n",
        "  print(\"WARNING: different number of classes in train and test\")\n",
        "n_classes = max(n_classes_train, n_classes_test)\n",
        "y_train_one_hot = to_categorical(y_train) #specify number of classes explicity - may need to recode classes sequentially (1-9) to work correctly\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "print(y_train_one_hot)\n",
        "print(y_test_one_hot)\n",
        "\t\n",
        "\t#---- Adding the features and reshaping the data if necessary\n",
        "X_train = addingfeat_reshape_data(X_train, feature, n_channels) #Feature = \"SB\" (spectral bands)\n",
        "\n",
        "print(X_train[0, :, :])\n",
        "print(X_train.shape)\n",
        "X_test = addingfeat_reshape_data(X_test, feature, n_channels)\t\t\n",
        "print(X_test.shape)\n",
        "\n",
        "#---- Normalizing the data per band (Do we want to normalize across years or within one year?)\n",
        "minMaxVal_file = '.'.join(out_model_file.split('.')[0:-1])\n",
        "minMaxVal_file = minMaxVal_file + '_minMax.txt'\n",
        "\n",
        "if not os.path.exists(minMaxVal_file): \n",
        "  min_per, max_per = computingMinMax(X_train) #compute 98% min/max (per = 2) on bands\n",
        "  save_minMaxVal(minMaxVal_file, min_per, max_per)\n",
        "else:\n",
        "  min_per, max_per = read_minMaxVal(minMaxVal_file)\n",
        "\n",
        "print(min_per, max_per)\n",
        "\n",
        "X_train =  normalizingData(X_train, min_per, max_per)\n",
        "X_test =  normalizingData(X_test, min_per, max_per)\n",
        "\n",
        "print(X_train) #verify normalization worked as intended\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OU_UXMDzkVni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Keras Model Architectures\n",
        "\n",
        "https://github.com/charlotte-pel/temporalCNN/\n"
      ],
      "metadata": {
        "id": "JVWSC7qXuSW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" \n",
        "\tDefining keras architecre, and training the models\n",
        "\"\"\"\n",
        "\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, Flatten, Lambda, SpatialDropout1D, Concatenate\n",
        "from keras.layers import Conv1D, Conv2D, AveragePooling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.callbacks import Callback, ModelCheckpoint, History, EarlyStopping\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import *\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "#---------------------- Modules\n",
        "#-----------------------------------------------------------------------\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv_bn(X, **conv_params):\t\n",
        "\tnbunits = conv_params[\"nbunits\"];\n",
        "\tkernel_size = conv_params[\"kernel_size\"];\n",
        "\n",
        "\tstrides = conv_params.setdefault(\"strides\", 1)\n",
        "\tpadding = conv_params.setdefault(\"padding\", \"same\")\n",
        "\tkernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-6))\n",
        "\tkernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "\n",
        "\tZ = Conv1D(nbunits, kernel_size=kernel_size, \n",
        "\t\t\tstrides = strides, padding=padding,\n",
        "\t\t\tkernel_initializer=kernel_initializer,\n",
        "\t\t\tkernel_regularizer=kernel_regularizer)(X)\n",
        "\n",
        "\treturn BatchNormalization(axis=-1)(Z) #-- CHANNEL_AXIS (-1)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv_bn_relu(X, **conv_params):\n",
        "\tZnorm = conv_bn(X, **conv_params)\n",
        "\treturn Activation('relu')(Znorm)\n",
        "\t\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv_bn_relu_drop(X, **conv_params):\t\n",
        "\tdropout_rate = conv_params.setdefault(\"dropout_rate\", 0.5)\n",
        "\tA = conv_bn_relu(X, **conv_params)\n",
        "\treturn Dropout(dropout_rate)(A)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv_bn_relu_spadrop(X, **conv_params):\t\n",
        "\tdropout_rate = conv_params.setdefault(\"dropout_rate\", 0.5)\n",
        "\tA = conv_bn_relu(X, **conv_params)\n",
        "\treturn SpatialDropout1D(dropout_rate)(A)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv2d_bn(X, **conv_params):\t\n",
        "\tnbunits = conv_params[\"nbunits\"];\n",
        "\tkernel_size = conv_params[\"kernel_size\"];\n",
        "\n",
        "\tstrides = conv_params.setdefault(\"strides\", 1)\n",
        "\tpadding = conv_params.setdefault(\"padding\", \"same\")\n",
        "\tkernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-6))\n",
        "\tkernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "\n",
        "\tZ = Conv2D(nbunits, kernel_size=kernel_size, \n",
        "\t\t\tstrides = strides, padding=padding,\n",
        "\t\t\tkernel_initializer=kernel_initializer,\n",
        "\t\t\tkernel_regularizer=kernel_regularizer)(X)\n",
        "\n",
        "\treturn BatchNormalization(axis=-1)(Z) #-- CHANNEL_AXIS (-1)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv2d_bn_relu(X, **conv_params):\n",
        "\tZnorm = conv2d_bn(X, **conv_params)\n",
        "\treturn Activation('relu')(Znorm)\n",
        "\t\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv2d_bn_relu_drop(X, **conv_params):\t\n",
        "\tdropout_rate = conv_params.setdefault(\"dropout_rate\", 0.5)\n",
        "\tA = conv2d_bn_relu(X, **conv_params)\n",
        "\treturn Dropout(dropout_rate)(A)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def conv2d_bn_relu_spadrop(X, **conv_params):\t\n",
        "\tdropout_rate = conv_params.setdefault(\"dropout_rate\", 0.5)\n",
        "\tA = conv2d_bn_relu(X, **conv_params)\n",
        "\treturn SpatialDropout1D(dropout_rate)(A)\n",
        "\n",
        "\t\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def relu_drop(X, **conv_params):\t\n",
        "\tdropout_rate = conv_params.setdefault(\"dropout_rate\", 0.5)\n",
        "\tA = Activation('relu')(X)\n",
        "\treturn Dropout(dropout_rate)(A)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def fc_bn(X, **fc_params):\n",
        "\tnbunits = fc_params[\"nbunits\"];\n",
        "\t\n",
        "\tkernel_regularizer = fc_params.setdefault(\"kernel_regularizer\", l2(1.e-6))\n",
        "\tkernel_initializer = fc_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "\t\t\n",
        "\tZ = Dense(nbunits, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(X)\n",
        "\treturn BatchNormalization(axis=-1)(Z) #-- CHANNEL_AXIS (-1)\n",
        "\t\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def fc_bn_relu(X, **fc_params):\t\n",
        "\tZnorm = fc_bn(X, **fc_params)\n",
        "\treturn Activation('relu')(Znorm)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def fc_bn_relu_drop(X, **fc_params):\n",
        "\tdropout_rate = fc_params.setdefault(\"dropout_rate\", 0.5)\n",
        "\tA = fc_bn_relu(X, **fc_params)\n",
        "\treturn Dropout(dropout_rate)(A)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def softmax(X, nbclasses, **params):\n",
        "\tkernel_regularizer = params.setdefault(\"kernel_regularizer\", l2(1.e-6))\n",
        "\tkernel_initializer = params.setdefault(\"kernel_initializer\", \"glorot_uniform\")\n",
        "\treturn Dense(nbclasses, activation='softmax', \n",
        "\t\t\tkernel_initializer=kernel_initializer,\n",
        "\t\t\tkernel_regularizer=kernel_regularizer)(X)\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def getNoClasses(model_path):\n",
        "\tmodel = load_model(model_path)\n",
        "\tlast_weight = model.get_weights()[-1]\n",
        "\tnclasses = last_weight.shape[0] #--- get size of the bias in the Softmax\n",
        "\treturn nclasses\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "#---------------------- Training models\n",
        "#-----------------------------------------------------------------------\n",
        "#-----------------------------------------------------------------------\n",
        "def trainTestModel(model, X_train, Y_train_onehot, X_test, Y_test_onehot, out_model_file, **train_params):\n",
        "\t#---- variables\n",
        "\tn_epochs = train_params.setdefault(\"n_epochs\", 20)\n",
        "\tbatch_size = train_params.setdefault(\"batch_size\", 32)\n",
        "\t\n",
        "\tlr = train_params.setdefault(\"lr\", 0.001)\n",
        "\tbeta_1 = train_params.setdefault(\"beta_1\", 0.9)\n",
        "\tbeta_2 = train_params.setdefault(\"beta_2\", 0.999)\n",
        "\tdecay = train_params.setdefault(\"decay\", 0.0)\n",
        "\n",
        "\t#---- optimizer\n",
        "\topt = tf.keras.optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, decay=decay)\n",
        "\tmodel.compile(optimizer = opt, loss = \"categorical_crossentropy\",\n",
        "\t\t\tmetrics = [\"accuracy\"])\n",
        "\t\n",
        "\t#---- monitoring the minimum loss\n",
        "\tcheckpoint = ModelCheckpoint(out_model_file, monitor='loss',\n",
        "\t\t\tverbose=0, save_best_only=True, mode='min')\n",
        "\tcallback_list = [checkpoint]\n",
        "\t\t\n",
        "\tstart_train_time = time.time()\n",
        "\thist = model.fit(x = X_train, y = Y_train_onehot, epochs = n_epochs, \n",
        "\t\tbatch_size = batch_size, shuffle=True,\n",
        "\t\tvalidation_data=(X_test, Y_test_onehot),\n",
        "\t\tverbose=1, callbacks=callback_list)\n",
        "\ttrain_time = round(time.time()-start_train_time, 2)\n",
        "\t\t\n",
        "\t#-- download the best model\n",
        "\tdel model\t\n",
        "\tmodel = load_model(out_model_file)\n",
        "\tstart_test_time = time.time()\n",
        "\ttest_loss, test_acc = model.evaluate(x=X_test, y=Y_test_onehot, \n",
        "\t\tbatch_size = 128, verbose=0)\n",
        "\ttest_time = round(time.time()-start_test_time, 2)\n",
        "\t\n",
        "\treturn test_acc, np.min(hist.history['loss']), model, hist.history, train_time, test_time\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "def trainTestModel_EarlyAbandon(model, X_train, Y_train_onehot, X_test, Y_test_onehot, out_model_file, **train_params):\n",
        "\t#---- variables\n",
        "\tn_epochs = train_params.setdefault(\"n_epochs\", 20)\n",
        "\tbatch_size = train_params.setdefault(\"batch_size\", 32)\n",
        "\t\n",
        "\tlr = train_params.setdefault(\"lr\", 0.001)\n",
        "\tbeta_1 = train_params.setdefault(\"beta_1\", 0.9)\n",
        "\tbeta_2 = train_params.setdefault(\"beta_2\", 0.999)\n",
        "\tdecay = train_params.setdefault(\"decay\", 0.0)\n",
        "\n",
        "\t#---- optimizer\n",
        "\topt = tf.keras.optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, decay=decay)\n",
        "\tmodel.compile(optimizer = opt, loss = \"categorical_crossentropy\",\n",
        "\t\t\tmetrics = [\"accuracy\"])\n",
        "\t\n",
        "\t#---- monitoring the minimum loss\n",
        "\tcheckpoint = ModelCheckpoint(out_model_file, monitor='loss',\n",
        "\t\t\tverbose=0, save_best_only=True, mode='min')\n",
        "\t#early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
        "  #callback_list = [checkpoint, early_stop]\n",
        "\tcallback_list = [checkpoint]\n",
        "\t\t\t\n",
        "\tstart_train_time = time.time()\n",
        "\thist = model.fit(x = X_train, y = Y_train_onehot, epochs = n_epochs, \n",
        "\t\tbatch_size = batch_size, shuffle=True,\n",
        "\t\tvalidation_data=(X_test, Y_test_onehot),\n",
        "\t\tverbose=1, callbacks=callback_list)\n",
        "\ttrain_time = round(time.time()-start_train_time, 2)\n",
        "\t\t\n",
        "\t#-- download the best model\n",
        "\tdel model\t\n",
        "\tmodel = load_model(out_model_file)\n",
        "\tstart_test_time = time.time()\n",
        "\ttest_loss, test_acc = model.evaluate(x=X_test, y=Y_test_onehot, \n",
        "\t\tbatch_size = 128, verbose=0)\n",
        "\ttest_time = round(time.time()-start_test_time, 2)\n",
        "\t\n",
        "\treturn test_acc, np.min(hist.history['loss']), model, hist.history, train_time, test_time\n",
        "\t\t\n",
        "#-----------------------------------------------------------------------\n",
        "def trainValTestModel(model, X_train, Y_train_onehot, X_val, Y_val_onehot, X_test, Y_test_onehot, out_model_file, **train_params):\n",
        "\t#---- variables\n",
        "\tn_epochs = train_params.setdefault(\"n_epochs\", 20)\n",
        "\tbatch_size = train_params.setdefault(\"batch_size\", 32)\n",
        "\t\n",
        "\tlr = train_params.setdefault(\"lr\", 0.001)\n",
        "\tbeta_1 = train_params.setdefault(\"beta_1\", 0.9)\n",
        "\tbeta_2 = train_params.setdefault(\"beta_2\", 0.999)\n",
        "\tdecay = train_params.setdefault(\"decay\", 0.0)\n",
        "\n",
        "\t#---- optimizer\n",
        "\topt = tf.keras.optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, decay=decay)\n",
        "\tmodel.compile(optimizer = opt, loss = \"categorical_crossentropy\",\n",
        "\t\t\tmetrics = [\"accuracy\"])\n",
        "\t\n",
        "\t#---- monitoring the minimum validation loss\n",
        "\tcheckpoint = ModelCheckpoint(out_model_file, monitor='val_loss',\n",
        "\t\t\tverbose=0, save_best_only=True, mode='min')\n",
        "\tcallback_list = [checkpoint]\n",
        "\t\t\n",
        "\tstart_train_time = time.time()\n",
        "\thist = model.fit(x = X_train, y = Y_train_onehot, epochs = n_epochs, \n",
        "\t\tbatch_size = batch_size, shuffle=True,\n",
        "\t\tvalidation_data=(X_val, Y_val_onehot),\n",
        "\t\tverbose=1, callbacks=callback_list)\n",
        "\ttrain_time = round(time.time()-start_train_time, 2)\n",
        "\t\t\n",
        "\t#-- download the best model\n",
        "\tdel model\t\n",
        "\tmodel = load_model(out_model_file)\n",
        "\tstart_test_time = time.time()\n",
        "\ttest_loss, test_acc = model.evaluate(x=X_test, y=Y_test_onehot, \n",
        "\t\tbatch_size = 128, verbose=0)\n",
        "\ttest_time = round(time.time()-start_test_time, 2)\n",
        "\t\n",
        "\treturn test_acc, np.min(hist.history['val_loss']), model, hist.history, train_time, test_time\n",
        "\t\n",
        "#-----------------------------------------------------------------------\n",
        "def trainValTestModel_EarlyAbandon(model, X_train, Y_train_onehot, X_val, Y_val_onehot, X_test, Y_test_onehot, out_model_file, **train_params):\n",
        "\t#---- variables\n",
        "\tn_epochs = train_params.setdefault(\"n_epochs\", 20)\n",
        "\tbatch_size = train_params.setdefault(\"batch_size\", 32)\n",
        "\t\n",
        "\tlr = train_params.setdefault(\"lr\", 0.001)\n",
        "\tbeta_1 = train_params.setdefault(\"beta_1\", 0.9)\n",
        "\tbeta_2 = train_params.setdefault(\"beta_2\", 0.999)\n",
        "\tdecay = train_params.setdefault(\"decay\", 0.0)\n",
        "\n",
        "\t#---- optimizer\n",
        "\topt = tf.keras.optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, decay=decay)\n",
        "\tmodel.compile(optimizer = opt, loss = \"categorical_crossentropy\",\n",
        "\t\t\tmetrics = [\"accuracy\"])\n",
        "\t\n",
        "\t#---- monitoring the minimum validation loss\n",
        "\tcheckpoint = ModelCheckpoint(out_model_file, monitor='val_loss',\n",
        "\t\t\tverbose=0, save_best_only=True, mode='min')\n",
        "\tearly_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
        "\tcallback_list = [checkpoint, early_stop]\n",
        "\t\t\n",
        "\tstart_train_time = time.time()\n",
        "\thist = model.fit(x = X_train, y = Y_train_onehot, epochs = n_epochs, \n",
        "\t\tbatch_size = batch_size, shuffle=True,\n",
        "\t\tvalidation_data=(X_val, Y_val_onehot),\n",
        "\t\tverbose=1, callbacks=callback_list)\n",
        "\ttrain_time = round(time.time()-start_train_time, 2)\n",
        "\t\t\n",
        "\t#-- download the best model\n",
        "\tdel model\t\n",
        "\tmodel = load_model(out_model_file)\n",
        "\tstart_test_time = time.time()\n",
        "\ttest_loss, test_acc = model.evaluate(x=X_test, y=Y_test_onehot, \n",
        "\t\tbatch_size = 128, verbose=0)\n",
        "\ttest_time = round(time.time()-start_test_time, 2)\n",
        "\t\n",
        "\treturn test_acc, np.min(hist.history['val_loss']), model, hist.history, train_time, test_time\n"
      ],
      "metadata": {
        "id": "33e3AXoOuhLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" \n",
        "\tDefining keras architecture.\n",
        "\t4.4. How big and deep model for our data?\n",
        "\t4.4.1. Width influence or the bias-variance trade-off\n",
        "\"\"\"\n",
        "\n",
        "import sys, os\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Flatten\n",
        "from keras import backend as K\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "#---------------------- ARCHITECTURES\n",
        "#------------------------------------------------------------------------\t\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV16_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 16 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV16_1FC256')\t\n",
        "\t\n",
        "\t\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV32_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 32 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV32_1FC256')\t\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV64_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 64 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV64_1FC256')\t\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV128_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 128 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV128_1FC256')\t\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV256_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 256 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV256_1FC256')\t\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV512_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 512 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV512_1FC256')\t\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------\t\t\n",
        "def Archi_3CONV1024_1FC256(X, nbclasses):\n",
        "\t\n",
        "\t#-- get the input sizes\n",
        "\tm, L, depth = X.shape\n",
        "\tinput_shape = (L,depth)\n",
        "\t\n",
        "\t#-- parameters of the architecture\n",
        "\tl2_rate = 1.e-6\n",
        "\tdropout_rate = 0.5\n",
        "\tnb_conv = 3\n",
        "\tnb_fc= 1\n",
        "\tnbunits_conv = 1024 #-- will be double\n",
        "\tnbunits_fc = 256 #-- will be double\n",
        "\t\n",
        "\t# Define the input placeholder.\n",
        "\tX_input = Input(input_shape)\n",
        "\t\t\n",
        "\t#-- nb_conv CONV layers\n",
        "\tX = X_input\n",
        "\tfor add in range(nb_conv):\n",
        "\t\tX = conv_bn_relu_drop(X, nbunits=nbunits_conv, kernel_size=5, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t#-- Flatten + \t1 FC layers\n",
        "\tX = Flatten()(X)\n",
        "\tfor add in range(nb_fc):\t\n",
        "\t\tX = fc_bn_relu_drop(X, nbunits=nbunits_fc, kernel_regularizer=l2(l2_rate), dropout_rate=dropout_rate)\n",
        "\t\t\n",
        "\t#-- SOFTMAX layer\n",
        "\tout = softmax(X, nbclasses, kernel_regularizer=l2(l2_rate))\n",
        "\t\t\n",
        "\t# Create model.\n",
        "\treturn Model(inputs = X_input, outputs = out, name='Archi_3CONV1024_1FC256')\t\n",
        "\n",
        "\n",
        "#--------------------- Switcher for running the architectures\n",
        "def runArchi(noarchi, *args):\n",
        "\t#---- variables\n",
        "\tn_epochs = 20\n",
        "\tbatch_size = 32\n",
        "\t\n",
        "\tswitcher = {\t\t\n",
        "\t\t0: Archi_3CONV16_1FC256,\n",
        "\t\t1: Archi_3CONV32_1FC256,\n",
        "\t\t2: Archi_3CONV64_1FC256,\n",
        "\t\t3: Archi_3CONV128_1FC256,\n",
        "\t\t3: Archi_3CONV256_1FC256,\n",
        "\t\t4: Archi_3CONV512_1FC256,\n",
        "\t\t5: Archi_3CONV1024_1FC256,\n",
        "\t}\n",
        "\tfunc = switcher.get(noarchi, lambda: 0)\n",
        "\tmodel = func(args[0], args[1].shape[1])\n",
        "\t\n",
        "\tif len(args)==5:\n",
        "\t\treturn trainTestModel_EarlyAbandon(model, *args, n_epochs=n_epochs, batch_size=batch_size)\n",
        "\telif len(args)==7:\n",
        "\t\treturn trainValTestModel_EarlyAbandon(model, *args, n_epochs=n_epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "y8Q2PrzhkVrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#---- Extracting a validation set (if necesary)\n",
        "if val_rate > 0:\n",
        "  X_train, y_train, X_val, y_val = extractValSet(X_train, polygon_ids_train, y_train, val_rate)\n",
        "  #--- Computing the one-hot encoding (recomputing it for train)\n",
        "  y_train_one_hot = to_categorical(y_train, n_classes)\n",
        "  y_val_one_hot = to_categorical(y_val, n_classes)\n",
        "\n",
        "if not os.path.isfile(res_file):\n",
        "  if val_rate==0:\n",
        "    res_mat[0,norun], res_mat[1,norun], model, model_hist, res_mat[2,norun], res_mat[3,norun] = runArchi(noarchi, X_train, y_train_one_hot, X_test, y_test_one_hot, out_model_file)\n",
        "  else:\n",
        "    res_mat[0,norun], res_mat[1,norun], model, model_hist, res_mat[2,norun], res_mat[3,norun] = runArchi(noarchi, X_train, y_train_one_hot, X_val, y_val_one_hot, X_test, y_test_one_hot, out_model_file)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VTjqSL-PkVtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_test_path = \"/content/drive/My\\ Drive/Invasives\\ Research\\ UMN/Remote\\ Sensing\\ Master/Leafy\\ Spurge\\ Demography/temporalCNN-master/example\"\n",
        "\n",
        "results_path = \"/content/drive/My\\ Drive/Invasives\\ Research\\ UMN/Remote\\ Sensing\\ Master/Leafy\\ Spurge\\ Demography/results\"\n",
        "\n",
        "!python3 '/content/drive/My Drive/Invasives Research UMN/Remote Sensing Master/Leafy Spurge Demography/temporalCNN-master/run_archi.py' '--sits_path' {train_test_path} '--res_path' {results_path} '--noarchi' 2\n",
        "\n"
      ],
      "metadata": {
        "id": "6-AgavJbkVxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oo-LtutnkVzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-8hofaqDkV19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SW-DVriekV38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5hUpXl_XkV5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cIMWzslqkV8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_e8-eG8JkV-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "512SjxdlkWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vd427Le_kWCK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}